{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character based POS-tagger for Biblical Hebrew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script you find a character based pos-tagger for Biblical Hebrew. The input of the model consists of clauses of Biblical Hebrew text and the output is a sequence of parts of speech. The model does not know where the word boundaries are, because the space is simply another character."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First some libraries are imported. These are Numpy, Keras and, of course, Text-Frabric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geitb\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF app is up-to-date.\n",
      "Using annotation/app-bhsa commit 43c1c5e88b371f575cdbbf57e38167deb8725f7f (=latest)\n",
      "  in C:\\Users\\geitb/text-fabric-data/__apps__/bhsa.\n",
      "Using etcbc/bhsa/tf - c r1.5 in C:\\Users\\geitb/text-fabric-data\n",
      "Using etcbc/phono/tf - c r1.2 in C:\\Users\\geitb/text-fabric-data\n",
      "Using etcbc/parallels/tf - c r1.2 in C:\\Users\\geitb/text-fabric-data\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Documentation:** <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa\" title=\"provenance of BHSA = Biblia Hebraica Stuttgartensia Amstelodamensis\">BHSA</a> <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Writing/Hebrew\" title=\"('Hebrew characters and transcriptions',)\">Character table</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/0_home.html\" title=\"BHSA feature documentation\">Feature docs</a> <a target=\"_blank\" href=\"https://github.com/annotation/app-bhsa\" title=\"bhsa API documentation\">bhsa API</a> <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Fabric/\" title=\"text-fabric-api\">Text-Fabric API 7.3.15</a> <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Use/Search/\" title=\"Search Templates Introduction and Reference\">Search Reference</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<details open><summary><b>Loaded features</b>:</summary>\n",
       "<p><b>BHSA = Biblia Hebraica Stuttgartensia Amstelodamensis</b>: <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/book.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\book.tf\">book</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/book@ll.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\book@am.tf\">book@ll</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/chapter.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\chapter.tf\">chapter</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/code.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\code.tf\">code</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/det.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\det.tf\">det</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/freq_lex.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\freq_lex.tf\">freq_lex</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/function.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\function.tf\">function</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/g_word.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\g_word.tf\">g_word</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/g_word_utf8.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\g_word_utf8.tf\">g_word_utf8</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/gloss.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\gloss.tf\">gloss</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/gn.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\gn.tf\">gn</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/label.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\label.tf\">label</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/language.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\language.tf\">language</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/lex.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\lex.tf\">lex</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/lex_utf8.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\lex_utf8.tf\">lex_utf8</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/ls.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\ls.tf\">ls</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/nametype.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\nametype.tf\">nametype</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/nu.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\nu.tf\">nu</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/number.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\number.tf\">number</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/otype.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\otype.tf\">otype</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/pdp.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\pdp.tf\">pdp</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/prs_gn.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\prs_gn.tf\">prs_gn</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/prs_nu.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\prs_nu.tf\">prs_nu</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/prs_ps.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\prs_ps.tf\">prs_ps</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/ps.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\ps.tf\">ps</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/qere.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\qere.tf\">qere</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/qere_trailer.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\qere_trailer.tf\">qere_trailer</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/qere_trailer_utf8.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\qere_trailer_utf8.tf\">qere_trailer_utf8</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/qere_utf8.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\qere_utf8.tf\">qere_utf8</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/rank_lex.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\rank_lex.tf\">rank_lex</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/rela.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\rela.tf\">rela</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/sp.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\sp.tf\">sp</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/st.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\st.tf\">st</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/trailer.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\trailer.tf\">trailer</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/trailer_utf8.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\trailer_utf8.tf\">trailer_utf8</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/txt.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\txt.tf\">txt</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/typ.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\typ.tf\">typ</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/verse.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\verse.tf\">verse</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/voc_lex.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\voc_lex.tf\">voc_lex</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/voc_lex_utf8.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\voc_lex_utf8.tf\">voc_lex_utf8</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/vs.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\vs.tf\">vs</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/vt.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\vt.tf\">vt</a>  <b><i><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/mother.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\mother.tf\">mother</a></i></b>  <b><i><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/oslots.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\oslots.tf\">oslots</a></i></b> </p><p><b>Parallel Passages</b>: <b><i><a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/etcbc/parallels/blob/master/programs/parallels.ipynb\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/parallels/tf/c\\crossref.tf\">crossref</a></i></b> </p><p><b>Phonetic Transcriptions</b>: <a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/etcbc/phono/blob/master/programs/phono.ipynb\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/phono/tf/c\\phono.tf\">phono</a>  <a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/etcbc/phono/blob/master/programs/phono.ipynb\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/phono/tf/c\\phono_trailer.tf\">phono_trailer</a> </p></details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@font-face {\n",
       "  font-family: \"Ezra SIL\";\n",
       "  src: url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SILEOT.ttf?raw=true');\n",
       "  src: url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SILEOT.woff?raw=true') format('woff');\n",
       "}\n",
       ".features {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0a6611;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    direction: ltr;\n",
       "}\n",
       ".features div,.features span {\n",
       "    padding: 0;\n",
       "    margin: -0.1rem 0;\n",
       "}\n",
       ".features .f {\n",
       "    font-family: sans-serif;\n",
       "    font-size: x-small;\n",
       "    font-weight: normal;\n",
       "    color: #5555bb;\n",
       "}\n",
       ".features .xft {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: medium;\n",
       "  margin: 0.1em 0em;\n",
       "}\n",
       ".features .xft .f {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-style: italic;\n",
       "  font-size: small;\n",
       "  font-weight: normal;\n",
       "}\n",
       ".verse {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: rtl;\n",
       "}\n",
       ".vl {\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    justify-content: flex-end;\n",
       "    align-items: flex-end;\n",
       "    direction: ltr;\n",
       "    width: 100%;\n",
       "}\n",
       ".outeritem {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: rtl;\n",
       "}\n",
       ".sentence,.clause,.phrase {\n",
       "    margin-top: -1.2em;\n",
       "    margin-left: 1em;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding: 0 0.3em;\n",
       "    border-style: solid;\n",
       "    border-radius: 0.2em;\n",
       "    font-size: small;\n",
       "    display: block;\n",
       "    width: fit-content;\n",
       "    max-width: fit-content;\n",
       "    direction: ltr;\n",
       "}\n",
       ".atoms {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    margin: 0.3em;\n",
       "    padding: 0.3em;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".satom,.catom,.patom {\n",
       "    margin: 0.3em;\n",
       "    padding: 0.3em;\n",
       "    border-radius: 0.3em;\n",
       "    border-style: solid;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".sentence {\n",
       "    border-color: #aa3333;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".clause {\n",
       "    border-color: #aaaa33;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".phrase {\n",
       "    border-color: #33aaaa;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".satom {\n",
       "    border-color: #aa3333;\n",
       "    border-width: 4px;\n",
       "}\n",
       ".catom {\n",
       "    border-color: #aaaa33;\n",
       "    border-width: 3px;\n",
       "}\n",
       ".patom {\n",
       "    border-color: #33aaaa;\n",
       "    border-width: 3px;\n",
       "}\n",
       ".word {\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    border-radius: 0.1em;\n",
       "    border: 1px solid #cccccc;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".lextp {\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    border-radius: 0.1em;\n",
       "    border: 2px solid #888888;\n",
       "    width: fit-content;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".occs {\n",
       "    font-size: x-small;\n",
       "}\n",
       ".satom.l,.catom.l,.patom.l {\n",
       "    border-left-style: dotted\n",
       "}\n",
       ".satom.r,.catom.r,.patom.r {\n",
       "    border-right-style: dotted\n",
       "}\n",
       ".satom.lno,.catom.lno,.patom.lno {\n",
       "    border-left-style: none\n",
       "}\n",
       ".satom.rno,.catom.rno,.patom.rno {\n",
       "    border-right-style: none\n",
       "}\n",
       ".tr,.tr a:visited,.tr a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: large;\n",
       "    color: #000044;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".trb,.trb a:visited,.trb a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: normal;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".prb,.prb a:visited,.prb a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: large;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".h,.h a:visited,.h a:link {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    color: #000044;\n",
       "    direction: rtl;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".hb,.hb a:visited,.hb a:link {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    line-height: 2;\n",
       "    direction: rtl;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".vn {\n",
       "  font-size: small !important;\n",
       "  padding-right: 1em;\n",
       "}\n",
       ".rela,.function,.typ {\n",
       "    font-family: monospace;\n",
       "    font-size: small;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".pdp,.pdp a:visited,.pdp a:link {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    color: #0000bb;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".voc_lex {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".vs {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".vt {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".gloss {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: normal;\n",
       "    color: #444444;\n",
       "}\n",
       ".vrs {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: #444444;\n",
       "}\n",
       ".nd {\n",
       "    font-family: monospace;\n",
       "    font-size: x-small;\n",
       "    color: #999999;\n",
       "}\n",
       ".hl {\n",
       "    background-color: #ffee66;\n",
       "}\n",
       "span.hldot {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder: 0.2rem solid var(--hl-rim);\n",
       "\tborder-radius: 0.4rem;\n",
       "\t/*\n",
       "\tdisplay: inline-block;\n",
       "\twidth: 0.8rem;\n",
       "\theight: 0.8rem;\n",
       "\t*/\n",
       "}\n",
       "span.hl {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder-width: 0;\n",
       "\tborder-radius: 0.1rem;\n",
       "\tborder-style: solid;\n",
       "}\n",
       "\n",
       "span.hlup {\n",
       "\tborder-color: var(--hl-dark);\n",
       "\tborder-width: 0.1rem;\n",
       "\tborder-style: solid;\n",
       "\tborder-radius: 0.2rem;\n",
       "  padding: 0.2rem;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--hl-strong:        hsla( 60, 100%,  70%, 0.9  );\n",
       "\t--hl-rim:           hsla( 55, 100%,  60%, 0.9  );\n",
       "\t--hl-dark:          hsla( 55, 100%,  40%, 0.9  );\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<details open><summary><b>API members</b>:</summary>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Computed/#computed-data\" title=\"doc\">C Computed</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Computed/#computed-data\" title=\"doc\">Call AllComputeds</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Computed/#computed-data\" title=\"doc\">Cs ComputedString</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Features/#edge-features\" title=\"doc\">E Edge</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Features/#edge-features\" title=\"doc\">Eall AllEdges</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Features/#edge-features\" title=\"doc\">Es EdgeString</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Fabric/#loading\" title=\"doc\">ensureLoaded</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Fabric/#loading\" title=\"doc\">TF</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Fabric/#loading\" title=\"doc\">ignored</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Fabric/#loading\" title=\"doc\">loadLog</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Locality/#locality\" title=\"doc\">L Locality</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Misc/#messaging\" title=\"doc\">cache</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Misc/#messaging\" title=\"doc\">error</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Misc/#messaging\" title=\"doc\">indent</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Misc/#messaging\" title=\"doc\">info</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Misc/#messaging\" title=\"doc\">reset</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Nodes/#navigating-nodes\" title=\"doc\">N Nodes</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Nodes/#navigating-nodes\" title=\"doc\">sortKey</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Nodes/#navigating-nodes\" title=\"doc\">sortKeyTuple</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Nodes/#navigating-nodes\" title=\"doc\">otypeRank</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Nodes/#navigating-nodes\" title=\"doc\">sortNodes</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Features/#node-features\" title=\"doc\">F Feature</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Features/#node-features\" title=\"doc\">Fall AllFeatures</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Features/#node-features\" title=\"doc\">Fs FeatureString</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Search/#search\" title=\"doc\">S Search</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Text/#text\" title=\"doc\">T Text</a></details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tf.app import use\n",
    "A = use('bhsa', hoist=globals())\n",
    "A.displaySetup(extraFeatures='g_cons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A train and test set are defined. The model is trained on all the books of the MT, except Jonah. The model will be used to predict parts of speech for this book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_books = ['Genesis', 'Exodus', 'Leviticus', 'Numbers', 'Deuteronomy', 'Joshua', 'Judges', '1_Samuel', \n",
    "               '2_Samuel','1_Kings', '2_Kings', 'Isaiah', 'Jeremiah', 'Ezekiel', 'Hosea', 'Joel', 'Amos', \n",
    "               'Obadiah', 'Micah', 'Nahum', 'Habakkuk', 'Zephaniah', 'Haggai', 'Zechariah', 'Malachi', \n",
    "               'Psalms', 'Job', 'Proverbs', 'Ruth', 'Song_of_songs', 'Ecclesiastes', 'Lamentations',\n",
    "               'Esther', 'Daniel', 'Ezra', 'Nehemiah', '1_Chronicles', '2_Chronicles']\n",
    "\n",
    "test_books = ['Jonah']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are prepared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_data(books):\n",
    "    \"\"\"\"\n",
    "    books is a list containing the books of the training set.\n",
    "    The function returns:\n",
    "    input_clauses is a list containing strings with the text of BH clauses\n",
    "    output_pos is a list containing lists with all the pos of BH clauses\n",
    "    input_chars is a list containing the characters occurring in the input_clauses (the input vocabulary)\n",
    "    output_vocab is a list containing all the pos occurring in the bhsa\n",
    "    max_len_input is the maximum length of all the input clauses in number of characters\n",
    "    max_len_output is the maximum length of all the output clauses in number of phrases (+2, because a \n",
    "    start and stop sign are added)\n",
    "    \"\"\"\n",
    "\n",
    "    input_clauses = []\n",
    "    output_pos = []\n",
    "    input_chars = set()\n",
    "    output_vocab = set()\n",
    "\n",
    "    for cl in F.otype.s(\"clause\"): \n",
    "        \n",
    "        bo, _, _ = T.sectionFromNode(cl)\n",
    "        if bo not in books:\n",
    "            continue\n",
    "        \n",
    "        # max length of a clause is 10 words\n",
    "        if len(L.d(cl, \"word\")) > 10:\n",
    "            continue\n",
    "        \n",
    "        # input and output is extracted from the bhsa\n",
    "        words = \" \".join([F.g_cons.v(w) for w in L.d(cl, \"word\")])\n",
    "        pos_prepare = [F.sp.v(w) for w in L.d(cl, \"word\")]\n",
    "        \n",
    "        poss = ['\\t']\n",
    "        for elem in pos_prepare:\n",
    "            poss.append(elem)\n",
    "        poss.append('\\n')\n",
    "    \n",
    "        input_clauses.append(words)\n",
    "        output_pos.append(poss)\n",
    "    \n",
    "        for ch in words:\n",
    "            input_chars.add(ch)\n",
    "            \n",
    "        for pos in poss:\n",
    "            output_vocab.add(pos)\n",
    "    \n",
    "    input_chars = sorted(list(input_chars))\n",
    "    output_vocab = sorted(list(output_vocab))\n",
    "    \n",
    "    max_len_input = max([len(clause) for clause in input_clauses])\n",
    "    max_len_output = max([len(poss) for poss in output_pos])\n",
    "    \n",
    "    return input_clauses, output_pos, input_chars, output_vocab, max_len_input, max_len_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_data(books):\n",
    "    \"\"\"\n",
    "    books is a list containing the test books\n",
    "    The function returns:\n",
    "    input_clauses, a list containing the text of clauses in the test books\n",
    "    \"\"\"\n",
    "\n",
    "    input_clauses_test = []\n",
    "    for cl in F.otype.s(\"clause\"): \n",
    "        \n",
    "        bo, _, _ = T.sectionFromNode(cl)\n",
    "        if bo not in books:\n",
    "            continue\n",
    "        \n",
    "        if len(L.d(cl, \"word\")) > 10:\n",
    "            continue\n",
    "\n",
    "        words = \" \".join([F.g_cons.v(w) for w in L.d(cl, \"word\")])\n",
    "        input_clauses_test.append(words)\n",
    "    \n",
    "    return input_clauses_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dicts(input_chars, output_vocab):\n",
    "    \"\"\"\n",
    "    The network can only handle numeric data. This function provides four dicts. \n",
    "    Two of them map between integers and the input characters (one dict for every direction), the other two \n",
    "    map between integers and parts of speech.\n",
    "    \"\"\"\n",
    "    \n",
    "    input_idx2char = {}\n",
    "    input_char2idx = {}\n",
    "\n",
    "    for k, v in enumerate(input_chars):\n",
    "        input_idx2char[k] = v\n",
    "        input_char2idx[v] = k\n",
    "        \n",
    "    output_idx2char = {}\n",
    "    output_char2idx = {}\n",
    "    \n",
    "    for k, v in enumerate(output_vocab):\n",
    "        output_idx2char[k] = v\n",
    "        output_char2idx[v] = k\n",
    "        \n",
    "    return input_idx2char, input_char2idx, output_idx2char, output_char2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(nb_samples, max_len_input, max_len_output, input_chars, output_vocab, input_char2idx, output_char2idx, input_clauses, output_pos):\n",
    "    \"\"\"\n",
    "    Categorical data are generally one-hot encoded in neural networks, which is done here.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    tokenized_input_data = np.zeros(shape = (nb_samples,max_len_input,len(input_chars)), dtype='float32')\n",
    "    tokenized_output = np.zeros(shape = (nb_samples,max_len_output,len(output_vocab)), dtype='float32')\n",
    "    target_data = np.zeros((nb_samples, max_len_output, len(output_vocab)),dtype='float32')\n",
    "\n",
    "    for i in range(nb_samples):\n",
    "        for k, ch in enumerate(input_clauses[i]):\n",
    "            tokenized_input_data[i, k, input_char2idx[ch]] = 1\n",
    "        \n",
    "        for k, ch in enumerate(output_pos[i]):\n",
    "            tokenized_output[i, k, output_char2idx[ch]] = 1\n",
    "\n",
    "            # decoder_target_data will be ahead by one timestep and will not include the start character.\n",
    "            if k > 0:\n",
    "                target_data[i, k-1, output_char2idx[ch]] = 1\n",
    "                \n",
    "    return tokenized_input_data, tokenized_output, target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_LSTM_model(input_chars, output_vocab):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Encoder model\n",
    "\n",
    "    encoder_input = Input(shape=(None,len(input_chars)))\n",
    "    encoder_LSTM = LSTM(512,activation = 'relu',return_state = True, return_sequences=True)(encoder_input)\n",
    "    encoder_LSTM = LSTM(512,return_state = True)(encoder_LSTM)\n",
    "    encoder_outputs, encoder_h, encoder_c = encoder_LSTM\n",
    "    encoder_states = [encoder_h, encoder_c]\n",
    "    \n",
    "    # Decoder model\n",
    "\n",
    "    decoder_input = Input(shape=(None,len(output_vocab)))\n",
    "    decoder_LSTM = LSTM(512, return_sequences=True, return_state = True)\n",
    "    decoder_out, _ , _ = decoder_LSTM(decoder_input, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(len(output_vocab), activation='softmax')\n",
    "    decoder_out = decoder_dense (decoder_out)\n",
    "    \n",
    "    model = Model(inputs=[encoder_input, decoder_input],outputs=[decoder_out])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return encoder_input, encoder_states, decoder_input, decoder_LSTM, decoder_dense, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_train(model, tokenized_input, tokenized_output, batch_size, epochs, validation_split):\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    model.fit(x=[tokenized_input,tokenized_output], \n",
    "              y=target_data,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_split=validation_split)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples = 70000\n",
    "\n",
    "input_clauses, output_pos, input_chars, output_vocab, max_len_input, max_len_output = prepare_train_data(train_books)\n",
    "input_idx2char, input_char2idx, output_idx2char, output_char2idx = create_dicts(input_chars, output_vocab)\n",
    "tokenized_input, tokenized_output, target_data = one_hot_encode(nb_samples, max_len_input, max_len_output, input_chars, output_vocab, input_char2idx, output_char2idx, input_clauses, output_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clauses = prepare_test_data(test_books)\n",
    "tokenized_test_data, _, _ = one_hot_encode(len(test_clauses), max_len_input, max_len_output, input_chars, output_vocab, input_char2idx, output_char2idx, test_clauses, output_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           (None, None, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_19 (LSTM)                  [(None, None, 512),  1101824     input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           (None, None, 16)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_20 (LSTM)                  [(None, 512), (None, 2099200     lstm_19[0][0]                    \n",
      "                                                                 lstm_19[0][1]                    \n",
      "                                                                 lstm_19[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_21 (LSTM)                  [(None, None, 512),  1083392     input_20[0][0]                   \n",
      "                                                                 lstm_20[0][1]                    \n",
      "                                                                 lstm_20[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, None, 16)     8208        lstm_21[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,292,624\n",
      "Trainable params: 4,292,624\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 63000 samples, validate on 7000 samples\n",
      "Epoch 1/70\n",
      "63000/63000 [==============================] - 52s 825us/step - loss: 0.7861 - val_loss: 0.6606\n",
      "Epoch 2/70\n",
      "63000/63000 [==============================] - 44s 699us/step - loss: 0.6634 - val_loss: 0.5711\n",
      "Epoch 3/70\n",
      "63000/63000 [==============================] - 44s 701us/step - loss: 0.6318 - val_loss: 0.5787\n",
      "Epoch 4/70\n",
      "63000/63000 [==============================] - 44s 702us/step - loss: 0.5980 - val_loss: 0.5530\n",
      "Epoch 5/70\n",
      "63000/63000 [==============================] - 44s 705us/step - loss: 0.5784 - val_loss: 0.5595\n",
      "Epoch 6/70\n",
      "63000/63000 [==============================] - 45s 707us/step - loss: 0.5473 - val_loss: 0.5091\n",
      "Epoch 7/70\n",
      "63000/63000 [==============================] - 44s 704us/step - loss: 0.5193 - val_loss: 0.4841\n",
      "Epoch 8/70\n",
      "63000/63000 [==============================] - 44s 706us/step - loss: 0.4964 - val_loss: 0.4656\n",
      "Epoch 9/70\n",
      "63000/63000 [==============================] - 44s 706us/step - loss: 0.4872 - val_loss: 0.4460\n",
      "Epoch 10/70\n",
      "63000/63000 [==============================] - 44s 704us/step - loss: 0.4749 - val_loss: 0.4367\n",
      "Epoch 11/70\n",
      "63000/63000 [==============================] - 44s 704us/step - loss: 0.4578 - val_loss: 0.4266\n",
      "Epoch 12/70\n",
      "63000/63000 [==============================] - 45s 710us/step - loss: 0.4450 - val_loss: 0.4114\n",
      "Epoch 13/70\n",
      "63000/63000 [==============================] - 45s 707us/step - loss: 0.4334 - val_loss: 0.4190\n",
      "Epoch 14/70\n",
      "63000/63000 [==============================] - 45s 710us/step - loss: 0.4264 - val_loss: 0.4050\n",
      "Epoch 15/70\n",
      "63000/63000 [==============================] - 46s 726us/step - loss: 0.4168 - val_loss: 0.3859\n",
      "Epoch 16/70\n",
      "63000/63000 [==============================] - 45s 710us/step - loss: 0.3936 - val_loss: 0.4555\n",
      "Epoch 17/70\n",
      "63000/63000 [==============================] - 45s 709us/step - loss: 0.3846 - val_loss: 0.3311\n",
      "Epoch 18/70\n",
      "63000/63000 [==============================] - 45s 711us/step - loss: 0.3189 - val_loss: 0.2705\n",
      "Epoch 19/70\n",
      "63000/63000 [==============================] - 45s 717us/step - loss: 0.2588 - val_loss: 0.2386\n",
      "Epoch 20/70\n",
      "63000/63000 [==============================] - 45s 717us/step - loss: 0.2141 - val_loss: 0.2200\n",
      "Epoch 21/70\n",
      "63000/63000 [==============================] - 45s 714us/step - loss: 0.2089 - val_loss: 0.1941\n",
      "Epoch 22/70\n",
      "63000/63000 [==============================] - 45s 715us/step - loss: 0.1698 - val_loss: 0.2052\n",
      "Epoch 23/70\n",
      "63000/63000 [==============================] - 45s 715us/step - loss: 0.1563 - val_loss: 0.2052\n",
      "Epoch 24/70\n",
      "63000/63000 [==============================] - 44s 703us/step - loss: 0.4989 - val_loss: 0.4322\n",
      "Epoch 25/70\n",
      "63000/63000 [==============================] - 44s 705us/step - loss: 0.4049 - val_loss: 0.3274\n",
      "Epoch 26/70\n",
      "63000/63000 [==============================] - 45s 714us/step - loss: 0.2439 - val_loss: 0.2030\n",
      "Epoch 27/70\n",
      "63000/63000 [==============================] - 45s 712us/step - loss: 0.1683 - val_loss: 0.1778\n",
      "Epoch 28/70\n",
      "63000/63000 [==============================] - 45s 714us/step - loss: 0.1444 - val_loss: 0.1777\n",
      "Epoch 29/70\n",
      "63000/63000 [==============================] - 45s 714us/step - loss: 0.1347 - val_loss: 0.1568\n",
      "Epoch 30/70\n",
      "63000/63000 [==============================] - 45s 714us/step - loss: 0.1195 - val_loss: 0.1517\n",
      "Epoch 31/70\n",
      "63000/63000 [==============================] - 45s 711us/step - loss: 0.1107 - val_loss: 0.1488\n",
      "Epoch 32/70\n",
      "63000/63000 [==============================] - 45s 712us/step - loss: 0.1039 - val_loss: 0.1895\n",
      "Epoch 33/70\n",
      "63000/63000 [==============================] - 45s 709us/step - loss: 0.2501 - val_loss: 0.4811\n",
      "Epoch 34/70\n",
      "63000/63000 [==============================] - 44s 706us/step - loss: 0.3742 - val_loss: 0.2239\n",
      "Epoch 35/70\n",
      "63000/63000 [==============================] - 45s 709us/step - loss: 0.1743 - val_loss: 0.1717\n",
      "Epoch 36/70\n",
      "63000/63000 [==============================] - 45s 708us/step - loss: 0.1316 - val_loss: 0.1513\n",
      "Epoch 37/70\n",
      "63000/63000 [==============================] - 45s 712us/step - loss: 0.1174 - val_loss: 0.1447\n",
      "Epoch 38/70\n",
      "63000/63000 [==============================] - 45s 710us/step - loss: 0.1036 - val_loss: 0.1453\n",
      "Epoch 39/70\n",
      "63000/63000 [==============================] - 45s 713us/step - loss: 0.0972 - val_loss: 0.1380\n",
      "Epoch 40/70\n",
      "63000/63000 [==============================] - 45s 712us/step - loss: 0.0903 - val_loss: 0.1353\n",
      "Epoch 41/70\n",
      "63000/63000 [==============================] - 45s 711us/step - loss: 0.0846 - val_loss: 0.1305\n",
      "Epoch 42/70\n",
      "63000/63000 [==============================] - 45s 712us/step - loss: 0.0802 - val_loss: 0.1491\n",
      "Epoch 43/70\n",
      "63000/63000 [==============================] - 45s 713us/step - loss: 0.0757 - val_loss: 0.1978\n",
      "Epoch 44/70\n",
      "63000/63000 [==============================] - 45s 710us/step - loss: 0.0739 - val_loss: 0.1352\n",
      "Epoch 45/70\n",
      "63000/63000 [==============================] - 45s 712us/step - loss: 0.0681 - val_loss: 0.1400\n",
      "Epoch 46/70\n",
      "63000/63000 [==============================] - 45s 712us/step - loss: 0.0641 - val_loss: 0.1324\n",
      "Epoch 47/70\n",
      "63000/63000 [==============================] - 45s 711us/step - loss: 0.0683 - val_loss: 0.1251\n",
      "Epoch 48/70\n",
      "63000/63000 [==============================] - 45s 711us/step - loss: 0.0765 - val_loss: 0.1211\n",
      "Epoch 49/70\n",
      "63000/63000 [==============================] - 45s 711us/step - loss: 0.0606 - val_loss: 0.1417\n",
      "Epoch 50/70\n",
      "63000/63000 [==============================] - 45s 710us/step - loss: 0.0565 - val_loss: 0.1354\n",
      "Epoch 51/70\n",
      "63000/63000 [==============================] - 45s 711us/step - loss: 0.0522 - val_loss: 0.1170\n",
      "Epoch 52/70\n",
      "63000/63000 [==============================] - 45s 714us/step - loss: 0.0486 - val_loss: 0.1247\n",
      "Epoch 53/70\n",
      "63000/63000 [==============================] - 45s 713us/step - loss: 0.0476 - val_loss: 0.1172\n",
      "Epoch 54/70\n",
      "63000/63000 [==============================] - 45s 711us/step - loss: 0.0436 - val_loss: 0.1193\n",
      "Epoch 55/70\n",
      "63000/63000 [==============================] - 45s 713us/step - loss: 0.0402 - val_loss: 0.1202\n",
      "Epoch 56/70\n",
      "63000/63000 [==============================] - 45s 711us/step - loss: 0.0374 - val_loss: 0.1219\n",
      "Epoch 57/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63000/63000 [==============================] - 45s 712us/step - loss: 0.0350 - val_loss: 0.1209\n",
      "Epoch 58/70\n",
      "63000/63000 [==============================] - 45s 711us/step - loss: 0.0314 - val_loss: 0.1267\n",
      "Epoch 59/70\n",
      "63000/63000 [==============================] - 45s 713us/step - loss: 0.0310 - val_loss: 0.1213\n",
      "Epoch 60/70\n",
      "63000/63000 [==============================] - 45s 712us/step - loss: 0.0288 - val_loss: 0.1251\n",
      "Epoch 61/70\n",
      "63000/63000 [==============================] - 45s 715us/step - loss: 0.0277 - val_loss: 0.1496\n",
      "Epoch 62/70\n",
      "63000/63000 [==============================] - 45s 710us/step - loss: 0.0245 - val_loss: 0.1470\n",
      "Epoch 63/70\n",
      "63000/63000 [==============================] - 45s 715us/step - loss: 0.0299 - val_loss: 0.1292\n",
      "Epoch 64/70\n",
      "63000/63000 [==============================] - 45s 715us/step - loss: 0.0212 - val_loss: 0.1357\n",
      "Epoch 65/70\n",
      "63000/63000 [==============================] - 45s 716us/step - loss: 0.0175 - val_loss: 0.1396\n",
      "Epoch 66/70\n",
      "63000/63000 [==============================] - 45s 712us/step - loss: 0.0194 - val_loss: 0.1389\n",
      "Epoch 67/70\n",
      "63000/63000 [==============================] - 45s 711us/step - loss: 0.0155 - val_loss: 0.1395\n",
      "Epoch 68/70\n",
      "63000/63000 [==============================] - 45s 711us/step - loss: 0.0131 - val_loss: 0.1545\n",
      "Epoch 69/70\n",
      "63000/63000 [==============================] - 45s 711us/step - loss: 0.0144 - val_loss: 0.1578\n",
      "Epoch 70/70\n",
      "63000/63000 [==============================] - 45s 713us/step - loss: 0.0206 - val_loss: 0.1472\n"
     ]
    }
   ],
   "source": [
    "encoder_input, encoder_states, decoder_input, decoder_LSTM, decoder_dense, model = define_LSTM_model(input_chars, output_vocab)\n",
    "model = compile_and_train(model, tokenized_input, tokenized_output, 512, 70, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference models for testing\n",
    "\n",
    "# Encoder inference model\n",
    "encoder_model_inf = Model(encoder_input, encoder_states)\n",
    "\n",
    "# Decoder inference model\n",
    "decoder_state_input_h = Input(shape=(512,))\n",
    "decoder_state_input_c = Input(shape=(512,))\n",
    "decoder_input_states = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_out, decoder_h, decoder_c = decoder_LSTM(decoder_input, \n",
    "                                                 initial_state=decoder_input_states)\n",
    "\n",
    "decoder_states = [decoder_h , decoder_c]\n",
    "\n",
    "decoder_out = decoder_dense(decoder_out)\n",
    "\n",
    "decoder_model_inf = Model(inputs=[decoder_input] + decoder_input_states,\n",
    "                          outputs=[decoder_out] + decoder_states )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_seq(inp_seq):\n",
    "    \n",
    "    # Initial states value is coming from the encoder \n",
    "    states_val = encoder_model_inf.predict(inp_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1, 1, len(output_vocab)))\n",
    "    target_seq[0, 0, output_char2idx['\\t']] = 1\n",
    "    \n",
    "    translated_sent = ''\n",
    "    pred_pos = []\n",
    "    stop_condition = False\n",
    "    \n",
    "    while not stop_condition:\n",
    "        \n",
    "        decoder_out, decoder_h, decoder_c = decoder_model_inf.predict(x=[target_seq] + states_val)\n",
    "        \n",
    "        max_val_index = np.argmax(decoder_out[0,-1,:])\n",
    "        sampled_out_char = output_idx2char[max_val_index]\n",
    "        pred_pos.append(sampled_out_char)\n",
    "        \n",
    "        if (sampled_out_char == '\\n'):\n",
    "            stop_condition = True\n",
    "        \n",
    "        target_seq = np.zeros((1, 1, len(output_vocab)))\n",
    "        target_seq[0, 0, max_val_index] = 1\n",
    "        \n",
    "        states_val = [decoder_h, decoder_c]\n",
    "        \n",
    "    return pred_pos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: W JHJ DBR JHWH >L JWNH BN >MTJ\n",
      "Decoded sentence: ['conj', 'verb', 'subs', 'nmpr', 'prep', 'subs', 'subs', 'subs']\n",
      "-\n",
      "Input sentence: L >MR\n",
      "Decoded sentence: ['prep', 'verb']\n",
      "-\n",
      "Input sentence: QWM\n",
      "Decoded sentence: ['verb']\n",
      "-\n",
      "Input sentence: LK >L NJNWH H <JR H GDWLH\n",
      "Decoded sentence: ['verb', 'prep', 'subs', 'art', 'subs', 'art', 'adjv']\n",
      "-\n",
      "Input sentence: W QR> <LJH\n",
      "Decoded sentence: ['conj', 'verb', 'prep']\n",
      "-\n",
      "Input sentence: KJ <LTH R<TM L PNJ\n",
      "Decoded sentence: ['conj', 'verb', 'subs', 'prep', 'subs']\n",
      "-\n",
      "Input sentence: W JQM JWNH\n",
      "Decoded sentence: ['conj', 'verb', 'nmpr']\n",
      "-\n",
      "Input sentence: L BRX TRCJCH M L PNJ JHWH\n",
      "Decoded sentence: ['prep', 'verb', 'nmpr', 'prep', 'prep', 'subs', 'nmpr']\n",
      "-\n",
      "Input sentence: W JRD JPW\n",
      "Decoded sentence: ['conj', 'verb', 'subs']\n",
      "-\n",
      "Input sentence: W JMY> >NJH\n",
      "Decoded sentence: ['conj', 'verb', 'nmpr']\n",
      "-\n",
      "Input sentence: B>H TRCJC\n",
      "Decoded sentence: ['verb', 'nmpr']\n",
      "-\n",
      "Input sentence: W JTN FKRH\n",
      "Decoded sentence: ['conj', 'verb', 'subs']\n",
      "-\n",
      "Input sentence: W JRD BH\n",
      "Decoded sentence: ['conj', 'verb', 'prep']\n",
      "-\n",
      "Input sentence: L BW> <MHM TRCJCH M L PNJ JHWH\n",
      "Decoded sentence: ['prep', 'verb', 'subs', 'adjv', 'prep', 'prep', 'subs', 'nmpr']\n",
      "-\n",
      "Input sentence: W JHWH HVJL RWX GDWLH >L H JM\n",
      "Decoded sentence: ['conj', 'nmpr', 'verb', 'subs', 'subs', 'prep', 'art', 'subs']\n",
      "-\n",
      "Input sentence: W JHJ S<R GDWL B  JM\n",
      "Decoded sentence: ['conj', 'verb', 'subs', 'adjv', 'prep', 'art', 'subs']\n",
      "-\n",
      "Input sentence: W H >NJH XCBH\n",
      "Decoded sentence: ['conj', 'art', 'subs', 'verb']\n",
      "-\n",
      "Input sentence: L HCBR\n",
      "Decoded sentence: ['prep', 'verb']\n",
      "-\n",
      "Input sentence: W JJR>W H MLXJM\n",
      "Decoded sentence: ['conj', 'verb', 'art', 'subs']\n",
      "-\n",
      "Input sentence: W JZ<QW\n",
      "Decoded sentence: ['conj', 'verb']\n",
      "-\n",
      "Input sentence: >JC >L >LHJW\n",
      "Decoded sentence: ['subs', 'prep', 'subs']\n",
      "-\n",
      "Input sentence: W JVLW >T H KLJM >L H JM\n",
      "Decoded sentence: ['conj', 'verb', 'prep', 'art', 'subs', 'prep', 'art', 'subs']\n",
      "-\n",
      "Input sentence: >CR B  >NJH\n",
      "Decoded sentence: ['conj', 'prep', 'art', 'subs']\n",
      "-\n",
      "Input sentence: L HQL M <LJHM\n",
      "Decoded sentence: ['prep', 'verb', 'prep', 'prep']\n",
      "-\n",
      "Input sentence: W JWNH JRD >L JRKTJ H SPJNH\n",
      "Decoded sentence: ['conj', 'nmpr', 'verb', 'prep', 'subs', 'art', 'nmpr']\n",
      "-\n",
      "Input sentence: W JCKB\n",
      "Decoded sentence: ['conj', 'verb']\n",
      "-\n",
      "Input sentence: W JRDM\n",
      "Decoded sentence: ['conj', 'verb']\n",
      "-\n",
      "Input sentence: W JQRB >LJW RB H XBL\n",
      "Decoded sentence: ['conj', 'verb', 'prep', 'subs', 'art', 'subs']\n",
      "-\n",
      "Input sentence: W J>MR LW\n",
      "Decoded sentence: ['conj', 'verb', 'prep']\n",
      "-\n",
      "Input sentence: MH LK\n",
      "Decoded sentence: ['prin', 'prep']\n",
      "-\n",
      "Input sentence: NRDM\n",
      "Decoded sentence: ['verb']\n",
      "-\n",
      "Input sentence: QWM\n",
      "Decoded sentence: ['verb']\n",
      "-\n",
      "Input sentence: QR> >L >LHJK\n",
      "Decoded sentence: ['verb', 'prep', 'subs']\n",
      "-\n",
      "Input sentence: >WLJ JT<CT H >LHJM LNW\n",
      "Decoded sentence: ['advb', 'verb', 'art', 'subs', 'prep']\n",
      "-\n",
      "Input sentence: W L> N>BD\n",
      "Decoded sentence: ['conj', 'nega', 'verb']\n",
      "-\n",
      "Input sentence: W J>MRW\n",
      "Decoded sentence: ['conj', 'verb']\n",
      "-\n",
      "Input sentence: >JC >L R<HW\n",
      "Decoded sentence: ['subs', 'prep', 'subs']\n",
      "-\n",
      "Input sentence: LKW\n",
      "Decoded sentence: ['verb']\n",
      "-\n",
      "Input sentence: W NPJLH GWRLWT\n",
      "Decoded sentence: ['conj', 'nmpr', 'verb']\n",
      "-\n",
      "Input sentence: W ND<H\n",
      "Decoded sentence: ['conj', 'verb']\n",
      "-\n",
      "Input sentence: B C L MJ H R<H H Z>T LNW\n",
      "Decoded sentence: ['prep', 'prep', 'prep', 'prep', 'art', 'subs', 'art', 'prde']\n",
      "-\n",
      "Input sentence: W JPLW GWRLWT\n",
      "Decoded sentence: ['conj', 'verb', 'subs']\n",
      "-\n",
      "Input sentence: W JPL H GWRL <L JWNH\n",
      "Decoded sentence: ['conj', 'verb', 'art', 'subs', 'prep', 'nmpr']\n",
      "-\n",
      "Input sentence: W J>MRW >LJW\n",
      "Decoded sentence: ['conj', 'verb', 'prep']\n",
      "-\n",
      "Input sentence: HGJDH N> LNW\n",
      "Decoded sentence: ['verb', 'intj', 'prep']\n",
      "-\n",
      "Input sentence: B >CR L MJ H R<H H Z>T LNW\n",
      "Decoded sentence: ['prep', 'conj', 'prep', 'subs', 'art', 'subs', 'art', 'prde', 'prep']\n",
      "-\n",
      "Input sentence: MH ML>KTK\n",
      "Decoded sentence: ['prin', 'subs']\n",
      "-\n",
      "Input sentence: W M >JN TBW>\n",
      "Decoded sentence: ['conj', 'prep', 'inrg', 'verb']\n",
      "-\n",
      "Input sentence: MH >RYK\n",
      "Decoded sentence: ['prin', 'subs']\n",
      "-\n",
      "Input sentence: W >J M ZH <M >TH\n",
      "Decoded sentence: ['conj', 'prin', 'prep', 'prde', 'prep', 'prps']\n",
      "-\n",
      "Input sentence: W J>MR >LJHM\n",
      "Decoded sentence: ['conj', 'verb', 'prep']\n",
      "-\n",
      "Input sentence: <BRJ >NKJ\n",
      "Decoded sentence: ['verb', 'prps']\n",
      "-\n",
      "Input sentence: W >T JHWH >LHJ H CMJM >NJ JR>\n",
      "Decoded sentence: ['conj', 'prep', 'nmpr', 'subs', 'art', 'subs', 'prps', 'verb']\n",
      "-\n",
      "Input sentence: >CR <FH >T H JM W >T H JBCH\n",
      "Decoded sentence: ['conj', 'verb', 'prep', 'art', 'subs', 'conj', 'prep', 'art', 'subs']\n",
      "-\n",
      "Input sentence: W JJR>W H >NCJM JR>H GDWLH\n",
      "Decoded sentence: ['conj', 'verb', 'art', 'subs', 'subs', 'adjv']\n",
      "-\n",
      "Input sentence: W J>MRW >LJW\n",
      "Decoded sentence: ['conj', 'verb', 'prep']\n",
      "-\n",
      "Input sentence: MH Z>T <FJT\n",
      "Decoded sentence: ['prin', 'prde', 'verb']\n",
      "-\n",
      "Input sentence: KJ JD<W H >NCJM\n",
      "Decoded sentence: ['conj', 'verb', 'art', 'subs']\n",
      "-\n",
      "Input sentence: KJ M L PNJ JHWH HW> BRX\n",
      "Decoded sentence: ['conj', 'prep', 'prep', 'subs', 'nmpr', 'prps', 'verb']\n",
      "-\n",
      "Input sentence: KJ HGJD LHM\n",
      "Decoded sentence: ['conj', 'verb', 'prep']\n",
      "-\n",
      "Input sentence: W J>MRW >LJW\n",
      "Decoded sentence: ['conj', 'verb', 'prep']\n",
      "-\n",
      "Input sentence: MH N<FH LK\n",
      "Decoded sentence: ['prin', 'verb', 'prep']\n",
      "-\n",
      "Input sentence: W JCTQ H JM M <LJNW\n",
      "Decoded sentence: ['conj', 'verb', 'art', 'subs', 'prep', 'prep']\n",
      "-\n",
      "Input sentence: KJ H JM HWLK\n",
      "Decoded sentence: ['conj', 'art', 'subs', 'verb']\n",
      "-\n",
      "Input sentence: W S<R\n",
      "Decoded sentence: ['conj', 'subs']\n",
      "-\n",
      "Input sentence: W J>MR >LJHM\n",
      "Decoded sentence: ['conj', 'verb', 'prep']\n",
      "-\n",
      "Input sentence: F>WNJ\n",
      "Decoded sentence: ['verb']\n",
      "-\n",
      "Input sentence: W HVJLNJ >L H JM\n",
      "Decoded sentence: ['conj', 'verb', 'prep', 'art', 'subs']\n",
      "-\n",
      "Input sentence: W JCTQ H JM M <LJKM\n",
      "Decoded sentence: ['conj', 'verb', 'art', 'subs', 'prep', 'prep']\n",
      "-\n",
      "Input sentence: KJ JWD< >NJ\n",
      "Decoded sentence: ['conj', 'verb', 'prps']\n",
      "-\n",
      "Input sentence: W JXTRW H >NCJM\n",
      "Decoded sentence: ['conj', 'verb', 'art', 'subs']\n",
      "-\n",
      "Input sentence: L HCJB >L H JBCH\n",
      "Decoded sentence: ['prep', 'verb', 'prep', 'art', 'subs']\n",
      "-\n",
      "Input sentence: W L> JKLW\n",
      "Decoded sentence: ['conj', 'nega', 'verb']\n",
      "-\n",
      "Input sentence: KJ H JM HWLK\n",
      "Decoded sentence: ['conj', 'art', 'subs', 'verb']\n",
      "-\n",
      "Input sentence: W S<R <LJHM\n",
      "Decoded sentence: ['conj', 'verb', 'prep']\n",
      "-\n",
      "Input sentence: W JQR>W >L JHWH\n",
      "Decoded sentence: ['conj', 'verb', 'prep', 'nmpr']\n",
      "-\n",
      "Input sentence: W J>MRW\n",
      "Decoded sentence: ['conj', 'verb']\n",
      "-\n",
      "Input sentence: >NH JHWH\n",
      "Decoded sentence: ['inrg', 'nmpr']\n",
      "-\n",
      "Input sentence: >L N> N>BDH B NPC H >JC H ZH\n",
      "Decoded sentence: ['nega', 'intj', 'verb', 'prep', 'art', 'subs', 'art', 'prde', 'art', 'prde']\n",
      "-\n",
      "Input sentence: W >L TTN <LJNW DM NQJ>\n",
      "Decoded sentence: ['conj', 'nega', 'verb', 'prep', 'subs', 'adjv']\n",
      "-\n",
      "Input sentence: KJ >TH <FJT\n",
      "Decoded sentence: ['conj', 'prps', 'verb']\n",
      "-\n",
      "Input sentence: JHWH\n",
      "Decoded sentence: ['nmpr']\n",
      "-\n",
      "Input sentence: K >CR XPYT\n",
      "Decoded sentence: ['prep', 'conj', 'verb']\n",
      "-\n",
      "Input sentence: W JF>W >T JWNH\n",
      "Decoded sentence: ['conj', 'verb', 'prep', 'nmpr']\n",
      "-\n",
      "Input sentence: W JVLHW >L H JM\n",
      "Decoded sentence: ['conj', 'verb', 'prep', 'art', 'subs']\n",
      "-\n",
      "Input sentence: W J<MD H JM M Z<PW\n",
      "Decoded sentence: ['conj', 'verb', 'art', 'subs', 'prep', 'subs']\n",
      "-\n",
      "Input sentence: W JJR>W H >NCJM JR>H GDWLH >T JHWH\n",
      "Decoded sentence: ['conj', 'verb', 'art', 'subs', 'subs', 'nmpr', 'prep', 'nmpr']\n",
      "-\n",
      "Input sentence: W JZBXW ZBX L JHWH\n",
      "Decoded sentence: ['conj', 'verb', 'subs', 'prep', 'nmpr']\n",
      "-\n",
      "Input sentence: W JDRW NDRJM\n",
      "Decoded sentence: ['conj', 'verb', 'subs']\n",
      "-\n",
      "Input sentence: W JMN JHWH DG GDWL\n",
      "Decoded sentence: ['conj', 'verb', 'nmpr', 'subs', 'adjv']\n",
      "-\n",
      "Input sentence: L BL< >T JWNH\n",
      "Decoded sentence: ['prep', 'verb', 'prep', 'nmpr']\n",
      "-\n",
      "Input sentence: W JTPLL JWNH >L JHWH >LHJW M M<J H DGH\n",
      "Decoded sentence: ['conj', 'verb', 'nmpr', 'prep', 'nmpr', 'subs', 'prep', 'subs', 'art', 'subs']\n",
      "-\n",
      "Input sentence: W J>MR\n",
      "Decoded sentence: ['conj', 'verb']\n",
      "-\n",
      "Input sentence: QR>TJ M YRH LJ >L JHWH\n",
      "Decoded sentence: ['verb', 'prep', 'subs', 'prep', 'prep', 'nmpr']\n",
      "-\n",
      "Input sentence: W J<NNJ\n",
      "Decoded sentence: ['conj', 'verb']\n",
      "-\n",
      "Input sentence: M BVN C>WL CW<TJ\n",
      "Decoded sentence: ['prep', 'subs', 'nmpr', 'verb']\n",
      "-\n",
      "Input sentence: CM<T QWLJ\n",
      "Decoded sentence: ['verb', 'subs']\n",
      "-\n",
      "Input sentence: W TCLJKNJ MYWLH B LBB JMJM\n",
      "Decoded sentence: ['conj', 'verb', 'subs', 'prep', 'subs', 'subs']\n",
      "-\n",
      "Input sentence: W NHR JSBBNJ\n",
      "Decoded sentence: ['conj', 'subs', 'verb']\n",
      "-\n",
      "Input sentence: KL MCBRJK W GLJK <LJ <BRW\n",
      "Decoded sentence: ['subs', 'subs', 'conj', 'subs', 'prep', 'verb']\n",
      "-\n",
      "Input sentence: W >NJ >MRTJ\n",
      "Decoded sentence: ['conj', 'prps', 'verb']\n",
      "-\n",
      "Input sentence: NGRCTJ M NGD <JNJK\n",
      "Decoded sentence: ['verb', 'prep', 'subs', 'subs']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: >K >WSJP\n",
      "Decoded sentence: ['advb', 'verb']\n",
      "-\n",
      "Input sentence: L HBJV >L HJKL QDCK\n",
      "Decoded sentence: ['prep', 'verb', 'prep', 'subs', 'subs']\n",
      "-\n",
      "Input sentence: >PPWNJ MJM <D NPC\n",
      "Decoded sentence: ['verb', 'subs', 'prep', 'subs']\n",
      "-\n",
      "Input sentence: THWM JSBBNJ\n",
      "Decoded sentence: ['subs', 'verb']\n",
      "-\n",
      "Input sentence: SWP XBWC L R>CJ\n",
      "Decoded sentence: ['verb', 'subs', 'prep', 'subs']\n",
      "-\n",
      "Input sentence: L QYBJ HRJM JRDTJ\n",
      "Decoded sentence: ['prep', 'subs', 'verb', 'verb']\n",
      "-\n",
      "Input sentence: H >RY\n",
      "Decoded sentence: ['art', 'subs']\n",
      "-\n",
      "Input sentence: BRXJH B<DJ L <WLM\n",
      "Decoded sentence: ['verb', 'subs', 'prep', 'subs']\n",
      "-\n",
      "Input sentence: W T<L M CXT XJJ\n",
      "Decoded sentence: ['conj', 'verb', 'prep', 'subs', 'nmpr']\n",
      "-\n",
      "Input sentence: JHWH >LHJ\n",
      "Decoded sentence: ['nmpr', 'subs']\n",
      "-\n",
      "Input sentence: B HT<VP <LJ NPCJ\n",
      "Decoded sentence: ['prep', 'verb', 'prep', 'subs']\n",
      "-\n",
      "Input sentence: >T JHWH ZKRTJ\n",
      "Decoded sentence: ['prep', 'nmpr', 'verb']\n",
      "-\n",
      "Input sentence: W TBW> >LJK TPLTJ >L HJKL QDCK\n",
      "Decoded sentence: ['conj', 'verb', 'prep', 'subs', 'prep', 'subs', 'subs']\n",
      "-\n",
      "Input sentence: MCMRJM HBLJ CW>\n",
      "Decoded sentence: ['verb', 'subs', 'subs']\n",
      "-\n",
      "Input sentence: XSDM J<ZBW\n",
      "Decoded sentence: ['subs', 'verb']\n",
      "-\n",
      "Input sentence: W >NJ\n",
      "Decoded sentence: ['conj', 'prps']\n",
      "-\n",
      "Input sentence: B QWL TWDH >ZBXH LK\n",
      "Decoded sentence: ['prep', 'subs', 'subs', 'verb', 'prep']\n",
      "-\n",
      "Input sentence: >CR NDRTJ\n",
      "Decoded sentence: ['conj', 'verb']\n",
      "-\n",
      "Input sentence: >CLMH\n",
      "Decoded sentence: ['verb']\n",
      "-\n",
      "Input sentence: JCW<TH L JHWH\n",
      "Decoded sentence: ['subs', 'prep', 'nmpr']\n",
      "-\n",
      "Input sentence: W J>MR JHWH L  DG\n",
      "Decoded sentence: ['conj', 'verb', 'nmpr', 'prep', 'art', 'subs']\n",
      "-\n",
      "Input sentence: W JQ> >T JWNH >L H JBCH\n",
      "Decoded sentence: ['conj', 'verb', 'prep', 'nmpr', 'prep', 'art', 'subs']\n",
      "-\n",
      "Input sentence: W JHJ DBR JHWH >L JWNH CNJT\n",
      "Decoded sentence: ['conj', 'verb', 'subs', 'nmpr', 'prep', 'subs', 'nmpr']\n",
      "-\n",
      "Input sentence: L >MR\n",
      "Decoded sentence: ['prep', 'verb']\n",
      "-\n",
      "Input sentence: QWM\n",
      "Decoded sentence: ['verb']\n",
      "-\n",
      "Input sentence: LK >L NJNWH H <JR H GDWLH\n",
      "Decoded sentence: ['verb', 'prep', 'subs', 'art', 'subs', 'art', 'adjv']\n",
      "-\n",
      "Input sentence: W QR> >LJH >T H QRJ>H\n",
      "Decoded sentence: ['conj', 'verb', 'prep', 'prep', 'art', 'subs']\n",
      "-\n",
      "Input sentence: >CR >NKJ DBR >LJK\n",
      "Decoded sentence: ['conj', 'prps', 'verb', 'prep']\n",
      "-\n",
      "Input sentence: W JQM JWNH\n",
      "Decoded sentence: ['conj', 'verb', 'nmpr']\n",
      "-\n",
      "Input sentence: W JLK >L NJNWH K DBR JHWH\n",
      "Decoded sentence: ['conj', 'verb', 'prep', 'nmpr', 'prep', 'subs', 'nmpr']\n",
      "-\n",
      "Input sentence: W NJNWH HJTH <JR GDWLH L >LHJM\n",
      "Decoded sentence: ['conj', 'nmpr', 'verb', 'subs', 'adjv', 'prep', 'subs']\n",
      "-\n",
      "Input sentence: MHLK CLCT JMJM\n",
      "Decoded sentence: ['verb', 'adjv', 'subs']\n",
      "-\n",
      "Input sentence: W JXL JWNH\n",
      "Decoded sentence: ['conj', 'verb', 'nmpr']\n",
      "-\n",
      "Input sentence: L BW> B  <JR MHLK JWM >XD\n",
      "Decoded sentence: ['prep', 'verb', 'prep', 'art', 'subs', 'prep', 'subs', 'subs']\n",
      "-\n",
      "Input sentence: W JQR>\n",
      "Decoded sentence: ['conj', 'verb']\n",
      "-\n",
      "Input sentence: W J>MR\n",
      "Decoded sentence: ['conj', 'verb']\n",
      "-\n",
      "Input sentence: <WD >RB<JM JWM\n",
      "Decoded sentence: ['subs', 'subs', 'subs']\n",
      "-\n",
      "Input sentence: W NJNWH NHPKT\n",
      "Decoded sentence: ['conj', 'nmpr', 'verb']\n",
      "-\n",
      "Input sentence: W J>MJNW >NCJ NJNWH B >LHJM\n",
      "Decoded sentence: ['conj', 'verb', 'subs', 'nmpr', 'prep', 'subs']\n",
      "-\n",
      "Input sentence: W JQR>W YWM\n",
      "Decoded sentence: ['conj', 'verb', 'subs']\n",
      "-\n",
      "Input sentence: W JLBCW FQJM M GDWLM W <D QVNM\n",
      "Decoded sentence: ['conj', 'verb', 'subs', 'prep', 'subs', 'conj', 'prep', 'adjv']\n",
      "-\n",
      "Input sentence: W JG< H DBR >L MLK NJNWH\n",
      "Decoded sentence: ['conj', 'verb', 'art', 'subs', 'prep', 'subs', 'nmpr']\n",
      "-\n",
      "Input sentence: W JQM M KS>W\n",
      "Decoded sentence: ['conj', 'verb', 'prep', 'subs']\n",
      "-\n",
      "Input sentence: W J<BR >DRTW M <LJW\n",
      "Decoded sentence: ['conj', 'verb', 'subs', 'prep', 'prep']\n",
      "-\n",
      "Input sentence: W JKS FQ\n",
      "Decoded sentence: ['conj', 'verb', 'subs']\n",
      "-\n",
      "Input sentence: W JCB <L H >PR\n",
      "Decoded sentence: ['conj', 'verb', 'prep', 'art', 'subs']\n",
      "-\n",
      "Input sentence: W JZ<Q\n",
      "Decoded sentence: ['conj', 'verb']\n",
      "-\n",
      "Input sentence: W J>MR\n",
      "Decoded sentence: ['conj', 'verb']\n",
      "-\n",
      "Input sentence: B NJNWH M V<M H MLK W GDLJW\n",
      "Decoded sentence: ['prep', 'subs', 'prep', 'subs', 'art', 'subs', 'conj', 'subs']\n",
      "-\n",
      "Input sentence: L >MR\n",
      "Decoded sentence: ['prep', 'verb']\n",
      "-\n",
      "Input sentence: >L JR<W\n",
      "Decoded sentence: ['nega', 'verb']\n",
      "-\n",
      "Input sentence: W MJM >L JCTW\n",
      "Decoded sentence: ['conj', 'subs', 'prep', 'verb']\n",
      "-\n",
      "Input sentence: W JTKSW FQJM H >DM W H BHMH\n",
      "Decoded sentence: ['conj', 'verb', 'subs', 'art', 'subs', 'conj', 'art', 'subs']\n",
      "-\n",
      "Input sentence: W JQR>W >L >LHJM B XZQH\n",
      "Decoded sentence: ['conj', 'verb', 'prep', 'subs', 'prep', 'nmpr']\n",
      "-\n",
      "Input sentence: W JCBW\n",
      "Decoded sentence: ['conj', 'verb']\n",
      "-\n",
      "Input sentence: >JC M DRKW H R<H W MN H XMS\n",
      "Decoded sentence: ['subs', 'prep', 'subs', 'art', 'subs', 'conj', 'prep', 'art', 'subs']\n",
      "-\n",
      "Input sentence: >CR B KPJHM\n",
      "Decoded sentence: ['conj', 'prep', 'subs']\n",
      "-\n",
      "Input sentence: MJ JWD<\n",
      "Decoded sentence: ['prin', 'verb']\n",
      "-\n",
      "Input sentence: JCWB\n",
      "Decoded sentence: ['verb']\n",
      "-\n",
      "Input sentence: W NXM H >LHJM\n",
      "Decoded sentence: ['conj', 'verb', 'art', 'subs']\n",
      "-\n",
      "Input sentence: W CB M XRWN >PW\n",
      "Decoded sentence: ['conj', 'verb', 'prep', 'subs', 'subs']\n",
      "-\n",
      "Input sentence: W L> N>BD\n",
      "Decoded sentence: ['conj', 'nega', 'verb']\n",
      "-\n",
      "Input sentence: W JR> H >LHJM >T M<FJHM\n",
      "Decoded sentence: ['conj', 'verb', 'art', 'subs', 'prep', 'subs']\n",
      "-\n",
      "Input sentence: KJ CBW M DRKM H R<H\n",
      "Decoded sentence: ['conj', 'verb', 'prep', 'subs', 'art', 'verb']\n",
      "-\n",
      "Input sentence: W JNXM H >LHJM <L H R<H\n",
      "Decoded sentence: ['conj', 'verb', 'art', 'subs', 'prep', 'art', 'subs']\n",
      "-\n",
      "Input sentence: >CR DBR\n",
      "Decoded sentence: ['conj', 'verb']\n",
      "-\n",
      "Input sentence: L <FWT LHM\n",
      "Decoded sentence: ['prep', 'verb', 'prep']\n",
      "-\n",
      "Input sentence: W L> <FH\n",
      "Decoded sentence: ['conj', 'nega', 'verb']\n",
      "-\n",
      "Input sentence: W JR< >L JWNH R<H GDWLH\n",
      "Decoded sentence: ['conj', 'verb', 'prep', 'subs', 'adjv', 'adjv']\n",
      "-\n",
      "Input sentence: W JXR LW\n",
      "Decoded sentence: ['conj', 'verb', 'prep']\n",
      "-\n",
      "Input sentence: W JTPLL >L JHWH\n",
      "Decoded sentence: ['conj', 'verb', 'prep', 'nmpr']\n",
      "-\n",
      "Input sentence: W J>MR\n",
      "Decoded sentence: ['conj', 'verb']\n",
      "-\n",
      "Input sentence: >NH JHWH\n",
      "Decoded sentence: ['inrg', 'nmpr']\n",
      "-\n",
      "Input sentence: H LW> ZH DBRJ\n",
      "Decoded sentence: ['inrg', 'nega', 'prde', 'subs']\n",
      "-\n",
      "Input sentence: <D HJWTJ <L >DMTJ\n",
      "Decoded sentence: ['prep', 'verb', 'prep', 'subs']\n",
      "-\n",
      "Input sentence: <L KN QDMTJ\n",
      "Decoded sentence: ['prep', 'advb', 'verb']\n",
      "-\n",
      "Input sentence: L BRX TRCJCH\n",
      "Decoded sentence: ['prep', 'verb', 'nmpr']\n",
      "-\n",
      "Input sentence: KJ JD<TJ\n",
      "Decoded sentence: ['conj', 'verb']\n",
      "-\n",
      "Input sentence: KJ >TH >L XNWN W RXWM\n",
      "Decoded sentence: ['conj', 'prps', 'subs', 'nmpr', 'conj', 'subs']\n",
      "-\n",
      "Input sentence: >RK >PJM\n",
      "Decoded sentence: ['adjv', 'subs']\n",
      "-\n",
      "Input sentence: W RB XSD\n",
      "Decoded sentence: ['conj', 'adjv', 'subs']\n",
      "-\n",
      "Input sentence: W NXM <L H R<H\n",
      "Decoded sentence: ['conj', 'verb', 'prep', 'art', 'subs']\n",
      "-\n",
      "Input sentence: W <TH\n",
      "Decoded sentence: ['conj', 'advb']\n",
      "-\n",
      "Input sentence: JHWH\n",
      "Decoded sentence: ['nmpr']\n",
      "-\n",
      "Input sentence: QX N> >T NPCJ MMNJ\n",
      "Decoded sentence: ['verb', 'intj', 'prep', 'subs', 'prep']\n",
      "-\n",
      "Input sentence: KJ VWB MWTJ M XJJ\n",
      "Decoded sentence: ['conj', 'adjv', 'subs', 'prep', 'adjv']\n",
      "-\n",
      "Input sentence: W J>MR JHWH\n",
      "Decoded sentence: ['conj', 'verb', 'nmpr']\n",
      "-\n",
      "Input sentence: H HJVB\n",
      "Decoded sentence: ['inrg', 'verb']\n",
      "-\n",
      "Input sentence: XRH LK\n",
      "Decoded sentence: ['verb', 'prep']\n",
      "-\n",
      "Input sentence: W JY> JWNH MN H <JR\n",
      "Decoded sentence: ['conj', 'verb', 'nmpr', 'prep', 'art', 'subs']\n",
      "-\n",
      "Input sentence: W JCB M QDM L  <JR\n",
      "Decoded sentence: ['conj', 'verb', 'prep', 'subs', 'prep', 'art', 'subs']\n",
      "-\n",
      "Input sentence: W J<F LW CM SKH\n",
      "Decoded sentence: ['conj', 'verb', 'prep', 'advb', 'subs']\n",
      "-\n",
      "Input sentence: W JCB TXTJH B  YL\n",
      "Decoded sentence: ['conj', 'verb', 'subs', 'prep', 'art', 'subs']\n",
      "-\n",
      "Input sentence: <D >CR JR>H\n",
      "Decoded sentence: ['prep', 'conj', 'verb']\n",
      "-\n",
      "Input sentence: MH JHJH B  <JR\n",
      "Decoded sentence: ['prin', 'verb', 'prep', 'art', 'subs']\n",
      "-\n",
      "Input sentence: W JMN JHWH >LHJM QJQJWN\n",
      "Decoded sentence: ['conj', 'verb', 'nmpr', 'subs', 'adjv']\n",
      "-\n",
      "Input sentence: W J<L M <L L JWNH\n",
      "Decoded sentence: ['conj', 'verb', 'prep', 'prep', 'prep', 'nmpr']\n",
      "-\n",
      "Input sentence: L HJWT YL <L R>CW\n",
      "Decoded sentence: ['prep', 'verb', 'subs', 'prep', 'subs']\n",
      "-\n",
      "Input sentence: L HYJL LW M R<TW\n",
      "Decoded sentence: ['prep', 'verb', 'prep', 'prep', 'subs']\n",
      "-\n",
      "Input sentence: W JFMX JWNH <L H QJQJWN FMXH GDWLH\n",
      "Decoded sentence: ['conj', 'verb', 'nmpr', 'prep', 'art', 'subs', 'subs', 'subs']\n",
      "-\n",
      "Input sentence: W JMN H >LHJM TWL<T\n",
      "Decoded sentence: ['conj', 'subs', 'art', 'subs', 'verb']\n",
      "-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: B <LWT H CXR L  MXRT\n",
      "Decoded sentence: ['prep', 'verb', 'art', 'subs', 'prep', 'art', 'subs']\n",
      "-\n",
      "Input sentence: W TK >T H QJQJWN\n",
      "Decoded sentence: ['conj', 'verb', 'prep', 'art', 'adjv']\n",
      "-\n",
      "Input sentence: W JJBC\n",
      "Decoded sentence: ['conj', 'verb']\n",
      "-\n",
      "Input sentence: W JHJ\n",
      "Decoded sentence: ['conj', 'verb']\n",
      "-\n",
      "Input sentence: K ZRX H CMC\n",
      "Decoded sentence: ['prep', 'verb', 'art', 'subs']\n",
      "-\n",
      "Input sentence: W JMN >LHJM RWX QDJM XRJCJT\n",
      "Decoded sentence: ['conj', 'verb', 'subs', 'subs', 'subs', 'adjv']\n",
      "-\n",
      "Input sentence: W TK H CMC <L R>C JWNH\n",
      "Decoded sentence: ['conj', 'verb', 'art', 'subs', 'prep', 'subs', 'nmpr']\n",
      "-\n",
      "Input sentence: W JT<LP\n",
      "Decoded sentence: ['conj', 'verb']\n",
      "-\n",
      "Input sentence: W JC>L >T NPCW\n",
      "Decoded sentence: ['conj', 'verb', 'prep', 'subs']\n",
      "-\n",
      "Input sentence: L MWT\n",
      "Decoded sentence: ['prep', 'verb']\n",
      "-\n",
      "Input sentence: W J>MR\n",
      "Decoded sentence: ['conj', 'verb']\n",
      "-\n",
      "Input sentence: VWB MWTJ M XJJ\n",
      "Decoded sentence: ['adjv', 'subs', 'prep', 'adjv']\n",
      "-\n",
      "Input sentence: W J>MR >LHJM >L JWNH\n",
      "Decoded sentence: ['conj', 'verb', 'subs', 'prep', 'nmpr']\n",
      "-\n",
      "Input sentence: H HJVB\n",
      "Decoded sentence: ['inrg', 'verb']\n",
      "-\n",
      "Input sentence: XRH LK <L H QJQJWN\n",
      "Decoded sentence: ['verb', 'prep', 'prep', 'art', 'subs']\n",
      "-\n",
      "Input sentence: W J>MR\n",
      "Decoded sentence: ['conj', 'verb']\n",
      "-\n",
      "Input sentence: HJVB\n",
      "Decoded sentence: ['verb']\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(220):\n",
    "    inp_seq = tokenized_test_data[seq_index:seq_index+1]\n",
    "    \n",
    "    pred_pos = decode_seq(inp_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', test_clauses[seq_index])\n",
    "    print('Decoded sentence:', pred_pos[:-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
