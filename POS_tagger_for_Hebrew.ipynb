{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character based POS-tagger for Biblical Hebrew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script you find a character based pos-tagger for Biblical Hebrew. The input of the model consists of clauses of Biblical Hebrew text and the output is a sequence of parts of speech. The model does not know where the word boundaries are, because the space is simply another character."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First some libraries are imported. These are Numpy, Keras and, of course, Text-Frabric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geitb\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF app is up-to-date.\n",
      "Using annotation/app-bhsa commit 43c1c5e88b371f575cdbbf57e38167deb8725f7f (=latest)\n",
      "  in C:\\Users\\geitb/text-fabric-data/__apps__/bhsa.\n",
      "Using etcbc/bhsa/tf - c r1.5 in C:\\Users\\geitb/text-fabric-data\n",
      "Using etcbc/phono/tf - c r1.2 in C:\\Users\\geitb/text-fabric-data\n",
      "Using etcbc/parallels/tf - c r1.2 in C:\\Users\\geitb/text-fabric-data\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Documentation:** <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa\" title=\"provenance of BHSA = Biblia Hebraica Stuttgartensia Amstelodamensis\">BHSA</a> <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Writing/Hebrew\" title=\"('Hebrew characters and transcriptions',)\">Character table</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/0_home.html\" title=\"BHSA feature documentation\">Feature docs</a> <a target=\"_blank\" href=\"https://github.com/annotation/app-bhsa\" title=\"bhsa API documentation\">bhsa API</a> <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Fabric/\" title=\"text-fabric-api\">Text-Fabric API 7.3.15</a> <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Use/Search/\" title=\"Search Templates Introduction and Reference\">Search Reference</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<details open><summary><b>Loaded features</b>:</summary>\n",
       "<p><b>BHSA = Biblia Hebraica Stuttgartensia Amstelodamensis</b>: <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/book.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\book.tf\">book</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/book@ll.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\book@am.tf\">book@ll</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/chapter.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\chapter.tf\">chapter</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/code.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\code.tf\">code</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/det.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\det.tf\">det</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/freq_lex.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\freq_lex.tf\">freq_lex</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/function.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\function.tf\">function</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/g_word.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\g_word.tf\">g_word</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/g_word_utf8.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\g_word_utf8.tf\">g_word_utf8</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/gloss.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\gloss.tf\">gloss</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/gn.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\gn.tf\">gn</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/label.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\label.tf\">label</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/language.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\language.tf\">language</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/lex.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\lex.tf\">lex</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/lex_utf8.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\lex_utf8.tf\">lex_utf8</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/ls.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\ls.tf\">ls</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/nametype.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\nametype.tf\">nametype</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/nu.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\nu.tf\">nu</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/number.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\number.tf\">number</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/otype.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\otype.tf\">otype</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/pdp.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\pdp.tf\">pdp</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/prs_gn.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\prs_gn.tf\">prs_gn</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/prs_nu.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\prs_nu.tf\">prs_nu</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/prs_ps.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\prs_ps.tf\">prs_ps</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/ps.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\ps.tf\">ps</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/qere.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\qere.tf\">qere</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/qere_trailer.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\qere_trailer.tf\">qere_trailer</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/qere_trailer_utf8.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\qere_trailer_utf8.tf\">qere_trailer_utf8</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/qere_utf8.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\qere_utf8.tf\">qere_utf8</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/rank_lex.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\rank_lex.tf\">rank_lex</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/rela.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\rela.tf\">rela</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/sp.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\sp.tf\">sp</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/st.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\st.tf\">st</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/trailer.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\trailer.tf\">trailer</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/trailer_utf8.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\trailer_utf8.tf\">trailer_utf8</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/txt.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\txt.tf\">txt</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/typ.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\typ.tf\">typ</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/verse.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\verse.tf\">verse</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/voc_lex.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\voc_lex.tf\">voc_lex</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/voc_lex_utf8.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\voc_lex_utf8.tf\">voc_lex_utf8</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/vs.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\vs.tf\">vs</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/vt.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\vt.tf\">vt</a>  <b><i><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/mother.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\mother.tf\">mother</a></i></b>  <b><i><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/oslots.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\oslots.tf\">oslots</a></i></b> </p><p><b>Parallel Passages</b>: <b><i><a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/etcbc/parallels/blob/master/programs/parallels.ipynb\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/parallels/tf/c\\crossref.tf\">crossref</a></i></b> </p><p><b>Phonetic Transcriptions</b>: <a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/etcbc/phono/blob/master/programs/phono.ipynb\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/phono/tf/c\\phono.tf\">phono</a>  <a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/etcbc/phono/blob/master/programs/phono.ipynb\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/phono/tf/c\\phono_trailer.tf\">phono_trailer</a> </p></details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@font-face {\n",
       "  font-family: \"Ezra SIL\";\n",
       "  src: url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SILEOT.ttf?raw=true');\n",
       "  src: url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SILEOT.woff?raw=true') format('woff');\n",
       "}\n",
       ".features {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0a6611;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    direction: ltr;\n",
       "}\n",
       ".features div,.features span {\n",
       "    padding: 0;\n",
       "    margin: -0.1rem 0;\n",
       "}\n",
       ".features .f {\n",
       "    font-family: sans-serif;\n",
       "    font-size: x-small;\n",
       "    font-weight: normal;\n",
       "    color: #5555bb;\n",
       "}\n",
       ".features .xft {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: medium;\n",
       "  margin: 0.1em 0em;\n",
       "}\n",
       ".features .xft .f {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-style: italic;\n",
       "  font-size: small;\n",
       "  font-weight: normal;\n",
       "}\n",
       ".verse {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: rtl;\n",
       "}\n",
       ".vl {\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    justify-content: flex-end;\n",
       "    align-items: flex-end;\n",
       "    direction: ltr;\n",
       "    width: 100%;\n",
       "}\n",
       ".outeritem {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: rtl;\n",
       "}\n",
       ".sentence,.clause,.phrase {\n",
       "    margin-top: -1.2em;\n",
       "    margin-left: 1em;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding: 0 0.3em;\n",
       "    border-style: solid;\n",
       "    border-radius: 0.2em;\n",
       "    font-size: small;\n",
       "    display: block;\n",
       "    width: fit-content;\n",
       "    max-width: fit-content;\n",
       "    direction: ltr;\n",
       "}\n",
       ".atoms {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    margin: 0.3em;\n",
       "    padding: 0.3em;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".satom,.catom,.patom {\n",
       "    margin: 0.3em;\n",
       "    padding: 0.3em;\n",
       "    border-radius: 0.3em;\n",
       "    border-style: solid;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".sentence {\n",
       "    border-color: #aa3333;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".clause {\n",
       "    border-color: #aaaa33;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".phrase {\n",
       "    border-color: #33aaaa;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".satom {\n",
       "    border-color: #aa3333;\n",
       "    border-width: 4px;\n",
       "}\n",
       ".catom {\n",
       "    border-color: #aaaa33;\n",
       "    border-width: 3px;\n",
       "}\n",
       ".patom {\n",
       "    border-color: #33aaaa;\n",
       "    border-width: 3px;\n",
       "}\n",
       ".word {\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    border-radius: 0.1em;\n",
       "    border: 1px solid #cccccc;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".lextp {\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    border-radius: 0.1em;\n",
       "    border: 2px solid #888888;\n",
       "    width: fit-content;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".occs {\n",
       "    font-size: x-small;\n",
       "}\n",
       ".satom.l,.catom.l,.patom.l {\n",
       "    border-left-style: dotted\n",
       "}\n",
       ".satom.r,.catom.r,.patom.r {\n",
       "    border-right-style: dotted\n",
       "}\n",
       ".satom.lno,.catom.lno,.patom.lno {\n",
       "    border-left-style: none\n",
       "}\n",
       ".satom.rno,.catom.rno,.patom.rno {\n",
       "    border-right-style: none\n",
       "}\n",
       ".tr,.tr a:visited,.tr a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: large;\n",
       "    color: #000044;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".trb,.trb a:visited,.trb a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: normal;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".prb,.prb a:visited,.prb a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: large;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".h,.h a:visited,.h a:link {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    color: #000044;\n",
       "    direction: rtl;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".hb,.hb a:visited,.hb a:link {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    line-height: 2;\n",
       "    direction: rtl;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".vn {\n",
       "  font-size: small !important;\n",
       "  padding-right: 1em;\n",
       "}\n",
       ".rela,.function,.typ {\n",
       "    font-family: monospace;\n",
       "    font-size: small;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".pdp,.pdp a:visited,.pdp a:link {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    color: #0000bb;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".voc_lex {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".vs {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".vt {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".gloss {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: normal;\n",
       "    color: #444444;\n",
       "}\n",
       ".vrs {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: #444444;\n",
       "}\n",
       ".nd {\n",
       "    font-family: monospace;\n",
       "    font-size: x-small;\n",
       "    color: #999999;\n",
       "}\n",
       ".hl {\n",
       "    background-color: #ffee66;\n",
       "}\n",
       "span.hldot {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder: 0.2rem solid var(--hl-rim);\n",
       "\tborder-radius: 0.4rem;\n",
       "\t/*\n",
       "\tdisplay: inline-block;\n",
       "\twidth: 0.8rem;\n",
       "\theight: 0.8rem;\n",
       "\t*/\n",
       "}\n",
       "span.hl {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder-width: 0;\n",
       "\tborder-radius: 0.1rem;\n",
       "\tborder-style: solid;\n",
       "}\n",
       "\n",
       "span.hlup {\n",
       "\tborder-color: var(--hl-dark);\n",
       "\tborder-width: 0.1rem;\n",
       "\tborder-style: solid;\n",
       "\tborder-radius: 0.2rem;\n",
       "  padding: 0.2rem;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--hl-strong:        hsla( 60, 100%,  70%, 0.9  );\n",
       "\t--hl-rim:           hsla( 55, 100%,  60%, 0.9  );\n",
       "\t--hl-dark:          hsla( 55, 100%,  40%, 0.9  );\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<details open><summary><b>API members</b>:</summary>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Computed/#computed-data\" title=\"doc\">C Computed</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Computed/#computed-data\" title=\"doc\">Call AllComputeds</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Computed/#computed-data\" title=\"doc\">Cs ComputedString</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Features/#edge-features\" title=\"doc\">E Edge</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Features/#edge-features\" title=\"doc\">Eall AllEdges</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Features/#edge-features\" title=\"doc\">Es EdgeString</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Fabric/#loading\" title=\"doc\">ensureLoaded</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Fabric/#loading\" title=\"doc\">TF</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Fabric/#loading\" title=\"doc\">ignored</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Fabric/#loading\" title=\"doc\">loadLog</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Locality/#locality\" title=\"doc\">L Locality</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Misc/#messaging\" title=\"doc\">cache</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Misc/#messaging\" title=\"doc\">error</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Misc/#messaging\" title=\"doc\">indent</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Misc/#messaging\" title=\"doc\">info</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Misc/#messaging\" title=\"doc\">reset</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Nodes/#navigating-nodes\" title=\"doc\">N Nodes</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Nodes/#navigating-nodes\" title=\"doc\">sortKey</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Nodes/#navigating-nodes\" title=\"doc\">sortKeyTuple</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Nodes/#navigating-nodes\" title=\"doc\">otypeRank</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Nodes/#navigating-nodes\" title=\"doc\">sortNodes</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Features/#node-features\" title=\"doc\">F Feature</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Features/#node-features\" title=\"doc\">Fall AllFeatures</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Features/#node-features\" title=\"doc\">Fs FeatureString</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Search/#search\" title=\"doc\">S Search</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Text/#text\" title=\"doc\">T Text</a></details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tf.app import use\n",
    "A = use('bhsa', hoist=globals())\n",
    "A.displaySetup(extraFeatures='g_cons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A train and test set are defined. The model is trained on all the books of the MT, except Jonah. The model will be used to predict parts of speech for this book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_books = ['Genesis', 'Exodus', 'Leviticus', 'Numbers', 'Deuteronomy', 'Joshua', 'Judges', '1_Samuel', \n",
    "               '2_Samuel','1_Kings', '2_Kings', 'Isaiah', 'Jeremiah', 'Ezekiel', 'Hosea', 'Joel', 'Amos', \n",
    "               'Obadiah', 'Micah', 'Nahum', 'Habakkuk', 'Zephaniah', 'Haggai', 'Zechariah', 'Malachi', \n",
    "               'Psalms', 'Job', 'Proverbs', 'Ruth', 'Song_of_songs', 'Ecclesiastes', 'Lamentations',\n",
    "               'Esther', 'Daniel', 'Ezra', 'Nehemiah', '1_Chronicles', '2_Chronicles']\n",
    "\n",
    "test_books = ['Jonah']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are prepared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_data(books):\n",
    "    \"\"\"\"\n",
    "    books is a list containing the books of the training set.\n",
    "    The function returns:\n",
    "    input_clauses is a list containing strings with the text of BH clauses\n",
    "    output_pos is a list containing lists with all the pos of BH clauses\n",
    "    input_chars is a list containing the characters occurring in the input_clauses (the input vocabulary)\n",
    "    output_vocab is a list containing all the pos occurring in the bhsa\n",
    "    max_len_input is the maximum length of all the input clauses in number of characters\n",
    "    max_len_output is the maximum length of all the output clauses in number of phrases (+2, because a \n",
    "    start and stop sign are added)\n",
    "    \"\"\"\n",
    "\n",
    "    input_clauses = []\n",
    "    output_pos = []\n",
    "    input_chars = set()\n",
    "    output_vocab = set()\n",
    "\n",
    "    for cl in F.otype.s(\"clause\"): \n",
    "        \n",
    "        bo, _, _ = T.sectionFromNode(cl)\n",
    "        if bo not in books:\n",
    "            continue\n",
    "        \n",
    "        # max length of a clause is 10 words\n",
    "        if len(L.d(cl, \"word\")) > 10:\n",
    "            continue\n",
    "        \n",
    "        # input and output is extracted from the bhsa\n",
    "        words = \" \".join([F.g_cons.v(w) for w in L.d(cl, \"word\")])\n",
    "        pos_prepare = [F.sp.v(w) for w in L.d(cl, \"word\")]\n",
    "        \n",
    "        poss = ['\\t']\n",
    "        for elem in pos_prepare:\n",
    "            poss.append(elem)\n",
    "        poss.append('\\n')\n",
    "    \n",
    "        input_clauses.append(words)\n",
    "        output_pos.append(poss)\n",
    "    \n",
    "        for ch in words:\n",
    "            if (ch not in input_chars):\n",
    "                input_chars.add(ch)\n",
    "            \n",
    "        for ch in poss:\n",
    "            if (ch not in output_vocab):\n",
    "                output_vocab.add(ch)\n",
    "                \n",
    "    output_vocab = sorted(list(output_vocab))\n",
    "    input_chars = sorted(list(input_chars))\n",
    "    \n",
    "    max_len_input = max([len(line) for line in input_clauses])\n",
    "    max_len_output = max([len(line) for line in output_pos])\n",
    "    \n",
    "    return input_clauses, output_pos, input_chars, output_vocab, max_len_input, max_len_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_data(books):\n",
    "    \"\"\"\n",
    "    books is a list containing the test books\n",
    "    The function returns:\n",
    "    input_clauses, a list containing the text of clauses in the test books\n",
    "    \"\"\"\n",
    "\n",
    "    input_clauses_test = []\n",
    "    for cl in F.otype.s(\"clause\"): \n",
    "        \n",
    "        bo, _, _ = T.sectionFromNode(cl)\n",
    "        if bo not in books:\n",
    "            continue\n",
    "        \n",
    "        if len(L.d(cl, \"word\")) > 10:\n",
    "            continue\n",
    "\n",
    "        words = \" \".join([F.g_cons.v(w) for w in L.d(cl, \"word\")])\n",
    "        input_clauses_test.append(words)\n",
    "    \n",
    "    return input_clauses_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dicts(input_chars, output_vocab):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    input_idx2char = {}\n",
    "    input_char2idx = {}\n",
    "\n",
    "    for k, v in enumerate(input_chars):\n",
    "        input_idx2char[k] = v\n",
    "        input_char2idx[v] = k\n",
    "        \n",
    "    output_idx2char = {}\n",
    "    output_char2idx = {}\n",
    "    \n",
    "    for k, v in enumerate(output_vocab):\n",
    "        output_idx2char[k] = v\n",
    "        output_char2idx[v] = k\n",
    "        \n",
    "    return input_idx2char, input_char2idx, output_idx2char, output_char2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(nb_samples, max_len_input, max_len_output, input_chars, output_vocab, input_char2idx, output_char2idx, input_clauses, output_pos):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    tokenized_input_data = np.zeros(shape = (nb_samples,max_len_input,len(input_chars)), dtype='float32')\n",
    "    tokenized_output = np.zeros(shape = (nb_samples,max_len_output,len(output_vocab)), dtype='float32')\n",
    "    target_data = np.zeros((nb_samples, max_len_output, len(output_vocab)),dtype='float32')\n",
    "\n",
    "    for i in range(nb_samples):\n",
    "        for k, ch in enumerate(input_clauses[i]):\n",
    "            tokenized_input_data[i, k, input_char2idx[ch]] = 1\n",
    "        \n",
    "        for k, ch in enumerate(output_pos[i]):\n",
    "            tokenized_output[i, k, output_char2idx[ch]] = 1\n",
    "\n",
    "            # decoder_target_data will be ahead by one timestep and will not include the start character.\n",
    "            if k > 0:\n",
    "                target_data[i, k-1, output_char2idx[ch]] = 1\n",
    "                \n",
    "    return tokenized_input_data, tokenized_output, target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_LSTM_model(input_chars, output_vocab):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Encoder model\n",
    "\n",
    "    encoder_input = Input(shape=(None,len(input_chars)))\n",
    "    encoder_LSTM = LSTM(512,activation = 'relu',return_state = True, return_sequences=True)(encoder_input)\n",
    "    encoder_LSTM = LSTM(512,return_state = True)(encoder_LSTM)\n",
    "    encoder_outputs, encoder_h, encoder_c = encoder_LSTM\n",
    "    encoder_states = [encoder_h, encoder_c]\n",
    "    \n",
    "    # Decoder model\n",
    "\n",
    "    decoder_input = Input(shape=(None,len(output_vocab)))\n",
    "    decoder_LSTM = LSTM(512, return_sequences=True, return_state = True)\n",
    "    decoder_out, _ , _ = decoder_LSTM(decoder_input, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(len(output_vocab), activation='softmax')\n",
    "    decoder_out = decoder_dense (decoder_out)\n",
    "    \n",
    "    model = Model(inputs=[encoder_input, decoder_input],outputs=[decoder_out])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return encoder_input, encoder_states, decoder_input, decoder_LSTM, decoder_dense, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_train(model, tokenized_input, tokenized_output, batch_size, epochs, validation_split):\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    model.fit(x=[tokenized_input,tokenized_output], \n",
    "              y=target_data,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_split=validation_split)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples = 30000\n",
    "\n",
    "input_clauses, output_pos, input_chars, output_vocab, max_len_input, max_len_output = prepare_train_data(train_books)\n",
    "input_idx2char, input_char2idx, output_idx2char, output_char2idx = create_dicts(input_chars, output_vocab)\n",
    "tokenized_input, tokenized_output, target_data = one_hot_encode(nb_samples, max_len_input, max_len_output, input_chars, output_vocab, input_char2idx, output_char2idx, input_clauses, output_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clauses = prepare_test_data(test_books)\n",
    "tokenized_test_data, _, _ = one_hot_encode(len(test_clauses), max_len_input, max_len_output, input_chars, output_vocab, input_char2idx, output_char2idx, test_clauses, output_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_35 (InputLayer)           (None, None, 25)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_34 (LSTM)                  [(None, None, 512),  1101824     input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_36 (InputLayer)           (None, None, 16)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_35 (LSTM)                  [(None, 512), (None, 2099200     lstm_34[0][0]                    \n",
      "                                                                 lstm_34[0][1]                    \n",
      "                                                                 lstm_34[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_36 (LSTM)                  [(None, None, 512),  1083392     input_36[0][0]                   \n",
      "                                                                 lstm_35[0][1]                    \n",
      "                                                                 lstm_35[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, None, 16)     8208        lstm_36[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,292,624\n",
      "Trainable params: 4,292,624\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 27000 samples, validate on 3000 samples\n",
      "Epoch 1/40\n",
      "27000/27000 [==============================] - 34s 1ms/step - loss: 0.8089 - val_loss: 0.7215\n",
      "Epoch 2/40\n",
      "27000/27000 [==============================] - 24s 905us/step - loss: 0.7039 - val_loss: 0.6741\n",
      "Epoch 3/40\n",
      "27000/27000 [==============================] - 24s 901us/step - loss: 0.6779 - val_loss: 0.6595\n",
      "Epoch 4/40\n",
      "27000/27000 [==============================] - 24s 905us/step - loss: 0.6691 - val_loss: 0.6518\n",
      "Epoch 5/40\n",
      "27000/27000 [==============================] - 25s 911us/step - loss: 0.6706 - val_loss: 0.6540\n",
      "Epoch 6/40\n",
      "27000/27000 [==============================] - 25s 919us/step - loss: 0.6660 - val_loss: 0.6788\n",
      "Epoch 7/40\n",
      "27000/27000 [==============================] - 24s 907us/step - loss: 0.6652 - val_loss: 0.6394\n",
      "Epoch 8/40\n",
      "27000/27000 [==============================] - 24s 901us/step - loss: 0.5874 - val_loss: 0.5388\n",
      "Epoch 9/40\n",
      "27000/27000 [==============================] - 25s 910us/step - loss: 0.5111 - val_loss: 0.4925\n",
      "Epoch 10/40\n",
      "27000/27000 [==============================] - 25s 922us/step - loss: 0.4706 - val_loss: 0.4549\n",
      "Epoch 11/40\n",
      "27000/27000 [==============================] - 25s 911us/step - loss: 0.4253 - val_loss: 0.4078\n",
      "Epoch 12/40\n",
      "27000/27000 [==============================] - 24s 903us/step - loss: 0.4048 - val_loss: 0.3717\n",
      "Epoch 13/40\n",
      "27000/27000 [==============================] - 24s 894us/step - loss: 0.3665 - val_loss: 0.3522\n",
      "Epoch 14/40\n",
      "27000/27000 [==============================] - 25s 908us/step - loss: 0.3240 - val_loss: 0.3050\n",
      "Epoch 15/40\n",
      "27000/27000 [==============================] - 25s 912us/step - loss: 0.2924 - val_loss: 0.2764\n",
      "Epoch 16/40\n",
      "27000/27000 [==============================] - 25s 917us/step - loss: 0.2901 - val_loss: 0.2600\n",
      "Epoch 17/40\n",
      "27000/27000 [==============================] - 25s 909us/step - loss: 0.2431 - val_loss: 0.2326\n",
      "Epoch 18/40\n",
      "27000/27000 [==============================] - 24s 906us/step - loss: 0.2125 - val_loss: 0.2232\n",
      "Epoch 19/40\n",
      "27000/27000 [==============================] - 25s 909us/step - loss: 0.1912 - val_loss: 0.1992\n",
      "Epoch 20/40\n",
      "27000/27000 [==============================] - 25s 910us/step - loss: 0.2034 - val_loss: 0.1970\n",
      "Epoch 21/40\n",
      "27000/27000 [==============================] - 25s 910us/step - loss: 0.1635 - val_loss: 0.1744\n",
      "Epoch 22/40\n",
      "27000/27000 [==============================] - 24s 905us/step - loss: 0.1465 - val_loss: 0.1629\n",
      "Epoch 23/40\n",
      "27000/27000 [==============================] - 25s 910us/step - loss: 0.1350 - val_loss: 0.1594\n",
      "Epoch 24/40\n",
      "27000/27000 [==============================] - 24s 905us/step - loss: 0.1230 - val_loss: 0.1461\n",
      "Epoch 25/40\n",
      "27000/27000 [==============================] - 25s 908us/step - loss: 0.1164 - val_loss: 0.1578\n",
      "Epoch 26/40\n",
      "27000/27000 [==============================] - 24s 901us/step - loss: 0.1031 - val_loss: 0.1354\n",
      "Epoch 27/40\n",
      "27000/27000 [==============================] - 24s 903us/step - loss: 0.0993 - val_loss: 0.1295\n",
      "Epoch 28/40\n",
      "27000/27000 [==============================] - 24s 906us/step - loss: 0.0885 - val_loss: 0.1286\n",
      "Epoch 29/40\n",
      "27000/27000 [==============================] - 24s 899us/step - loss: 0.0825 - val_loss: 0.1392\n",
      "Epoch 30/40\n",
      "27000/27000 [==============================] - 24s 904us/step - loss: 0.0736 - val_loss: 0.1242\n",
      "Epoch 31/40\n",
      "27000/27000 [==============================] - 25s 909us/step - loss: 0.0675 - val_loss: 0.1238\n",
      "Epoch 32/40\n",
      "27000/27000 [==============================] - 24s 904us/step - loss: 0.0629 - val_loss: 0.1162\n",
      "Epoch 33/40\n",
      "27000/27000 [==============================] - 24s 899us/step - loss: 0.0579 - val_loss: 0.1207\n",
      "Epoch 34/40\n",
      "27000/27000 [==============================] - 24s 907us/step - loss: 0.0524 - val_loss: 0.1138\n",
      "Epoch 35/40\n",
      "27000/27000 [==============================] - 24s 907us/step - loss: 0.0633 - val_loss: 0.1275\n",
      "Epoch 36/40\n",
      "27000/27000 [==============================] - 24s 907us/step - loss: 0.0470 - val_loss: 0.1242\n",
      "Epoch 37/40\n",
      "27000/27000 [==============================] - 24s 903us/step - loss: 0.0382 - val_loss: 0.1175\n",
      "Epoch 38/40\n",
      "27000/27000 [==============================] - 24s 899us/step - loss: 0.0343 - val_loss: 0.1167\n",
      "Epoch 39/40\n",
      "27000/27000 [==============================] - 24s 905us/step - loss: 0.0331 - val_loss: 0.1274\n",
      "Epoch 40/40\n",
      "27000/27000 [==============================] - 24s 904us/step - loss: 0.0330 - val_loss: 0.1196\n"
     ]
    }
   ],
   "source": [
    "encoder_input, encoder_states, decoder_input, decoder_LSTM, decoder_dense, model = define_LSTM_model(input_chars, output_vocab)\n",
    "model = compile_and_train(model, tokenized_input, tokenized_output, 256, 40, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference models for testing\n",
    "\n",
    "# Encoder inference model\n",
    "encoder_model_inf = Model(encoder_input, encoder_states)\n",
    "\n",
    "# Decoder inference model\n",
    "decoder_state_input_h = Input(shape=(512,))\n",
    "decoder_state_input_c = Input(shape=(512,))\n",
    "decoder_input_states = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_out, decoder_h, decoder_c = decoder_LSTM(decoder_input, \n",
    "                                                 initial_state=decoder_input_states)\n",
    "\n",
    "decoder_states = [decoder_h , decoder_c]\n",
    "\n",
    "decoder_out = decoder_dense(decoder_out)\n",
    "\n",
    "decoder_model_inf = Model(inputs=[decoder_input] + decoder_input_states,\n",
    "                          outputs=[decoder_out] + decoder_states )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_seq(inp_seq):\n",
    "    \n",
    "    # Initial states value is coming from the encoder \n",
    "    states_val = encoder_model_inf.predict(inp_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1, 1, len(output_vocab)))\n",
    "    target_seq[0, 0, output_char2idx['\\t']] = 1\n",
    "    \n",
    "    translated_sent = ''\n",
    "    stop_condition = False\n",
    "    \n",
    "    while not stop_condition:\n",
    "        \n",
    "        decoder_out, decoder_h, decoder_c = decoder_model_inf.predict(x=[target_seq] + states_val)\n",
    "        \n",
    "        max_val_index = np.argmax(decoder_out[0,-1,:])\n",
    "        sampled_out_char = output_idx2char[max_val_index]\n",
    "        translated_sent += sampled_out_char\n",
    "        \n",
    "        if (sampled_out_char == '\\n'):\n",
    "            stop_condition = True\n",
    "        \n",
    "        target_seq = np.zeros((1, 1, len(output_vocab)))\n",
    "        target_seq[0, 0, max_val_index] = 1\n",
    "        \n",
    "        states_val = [decoder_h, decoder_c]\n",
    "        \n",
    "    return translated_sent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: W JHJ DBR JHWH >L JWNH BN >MTJ\n",
      "Decoded sentence: conjverbsubsnmprprepnmprsubssubs\n",
      "\n",
      "-\n",
      "Input sentence: L >MR\n",
      "Decoded sentence: prepverb\n",
      "\n",
      "-\n",
      "Input sentence: QWM\n",
      "Decoded sentence: verb\n",
      "\n",
      "-\n",
      "Input sentence: LK >L NJNWH H <JR H GDWLH\n",
      "Decoded sentence: verbprepsubsartsubsartsubs\n",
      "\n",
      "-\n",
      "Input sentence: W QR> <LJH\n",
      "Decoded sentence: conjverbprep\n",
      "\n",
      "-\n",
      "Input sentence: KJ <LTH R<TM L PNJ\n",
      "Decoded sentence: conjverbsubsprepsubs\n",
      "\n",
      "-\n",
      "Input sentence: W JQM JWNH\n",
      "Decoded sentence: conjverbnmpr\n",
      "\n",
      "-\n",
      "Input sentence: L BRX TRCJCH M L PNJ JHWH\n",
      "Decoded sentence: prepverbsubsprepprepsubsnmpr\n",
      "\n",
      "-\n",
      "Input sentence: W JRD JPW\n",
      "Decoded sentence: conjverbsubs\n",
      "\n",
      "-\n",
      "Input sentence: W JMY> >NJH\n",
      "Decoded sentence: conjverbprep\n",
      "\n",
      "-\n",
      "Input sentence: B>H TRCJC\n",
      "Decoded sentence: verbsubs\n",
      "\n",
      "-\n",
      "Input sentence: W JTN FKRH\n",
      "Decoded sentence: conjverbsubs\n",
      "\n",
      "-\n",
      "Input sentence: W JRD BH\n",
      "Decoded sentence: conjverbprep\n",
      "\n",
      "-\n",
      "Input sentence: L BW> <MHM TRCJCH M L PNJ JHWH\n",
      "Decoded sentence: prepverbprepsubsprepprepsubsnmpr\n",
      "\n",
      "-\n",
      "Input sentence: W JHWH HVJL RWX GDWLH >L H JM\n",
      "Decoded sentence: conjnmprverbsubssubsprepartsubs\n",
      "\n",
      "-\n",
      "Input sentence: W JHJ S<R GDWL B  JM\n",
      "Decoded sentence: conjverbsubssubsprepartsubs\n",
      "\n",
      "-\n",
      "Input sentence: W H >NJH XCBH\n",
      "Decoded sentence: conjartsubsverb\n",
      "\n",
      "-\n",
      "Input sentence: L HCBR\n",
      "Decoded sentence: prepverb\n",
      "\n",
      "-\n",
      "Input sentence: W JJR>W H MLXJM\n",
      "Decoded sentence: conjverbartsubs\n",
      "\n",
      "-\n",
      "Input sentence: W JZ<QW\n",
      "Decoded sentence: conjverb\n",
      "\n",
      "-\n",
      "Input sentence: >JC >L >LHJW\n",
      "Decoded sentence: subsprepsubs\n",
      "\n",
      "-\n",
      "Input sentence: W JVLW >T H KLJM >L H JM\n",
      "Decoded sentence: conjverbprepartsubsprepartsubs\n",
      "\n",
      "-\n",
      "Input sentence: >CR B  >NJH\n",
      "Decoded sentence: conjprepartsubs\n",
      "\n",
      "-\n",
      "Input sentence: L HQL M <LJHM\n",
      "Decoded sentence: prepverbprepprep\n",
      "\n",
      "-\n",
      "Input sentence: W JWNH JRD >L JRKTJ H SPJNH\n",
      "Decoded sentence: conjnmprverbprepsubsartsubs\n",
      "\n",
      "-\n",
      "Input sentence: W JCKB\n",
      "Decoded sentence: conjverb\n",
      "\n",
      "-\n",
      "Input sentence: W JRDM\n",
      "Decoded sentence: conjverb\n",
      "\n",
      "-\n",
      "Input sentence: W JQRB >LJW RB H XBL\n",
      "Decoded sentence: conjverbprepsubsartsubs\n",
      "\n",
      "-\n",
      "Input sentence: W J>MR LW\n",
      "Decoded sentence: conjverbprep\n",
      "\n",
      "-\n",
      "Input sentence: MH LK\n",
      "Decoded sentence: prinprep\n",
      "\n",
      "-\n",
      "Input sentence: NRDM\n",
      "Decoded sentence: verb\n",
      "\n",
      "-\n",
      "Input sentence: QWM\n",
      "Decoded sentence: verb\n",
      "\n",
      "-\n",
      "Input sentence: QR> >L >LHJK\n",
      "Decoded sentence: verbprepsubs\n",
      "\n",
      "-\n",
      "Input sentence: >WLJ JT<CT H >LHJM LNW\n",
      "Decoded sentence: advbverbartsubsprep\n",
      "\n",
      "-\n",
      "Input sentence: W L> N>BD\n",
      "Decoded sentence: conjnegaverb\n",
      "\n",
      "-\n",
      "Input sentence: W J>MRW\n",
      "Decoded sentence: conjverb\n",
      "\n",
      "-\n",
      "Input sentence: >JC >L R<HW\n",
      "Decoded sentence: subsprepsubs\n",
      "\n",
      "-\n",
      "Input sentence: LKW\n",
      "Decoded sentence: verb\n",
      "\n",
      "-\n",
      "Input sentence: W NPJLH GWRLWT\n",
      "Decoded sentence: conjverbsubs\n",
      "\n",
      "-\n",
      "Input sentence: W ND<H\n",
      "Decoded sentence: conjverb\n",
      "\n",
      "-\n",
      "Input sentence: B C L MJ H R<H H Z>T LNW\n",
      "Decoded sentence: prepprinprepsubsartsubsartprdeverb\n",
      "\n",
      "-\n",
      "Input sentence: W JPLW GWRLWT\n",
      "Decoded sentence: conjverbadjv\n",
      "\n",
      "-\n",
      "Input sentence: W JPL H GWRL <L JWNH\n",
      "Decoded sentence: conjverbartsubsprepnmpr\n",
      "\n",
      "-\n",
      "Input sentence: W J>MRW >LJW\n",
      "Decoded sentence: conjverbprep\n",
      "\n",
      "-\n",
      "Input sentence: HGJDH N> LNW\n",
      "Decoded sentence: verbintjprep\n",
      "\n",
      "-\n",
      "Input sentence: B >CR L MJ H R<H H Z>T LNW\n",
      "Decoded sentence: prepconjprepsubsartsubsartprdeverb\n",
      "\n",
      "-\n",
      "Input sentence: MH ML>KTK\n",
      "Decoded sentence: prinverb\n",
      "\n",
      "-\n",
      "Input sentence: W M >JN TBW>\n",
      "Decoded sentence: conjprepprinverb\n",
      "\n",
      "-\n",
      "Input sentence: MH >RYK\n",
      "Decoded sentence: prinsubs\n",
      "\n",
      "-\n",
      "Input sentence: W >J M ZH <M >TH\n",
      "Decoded sentence: conjprepconjprepprdeprep\n",
      "\n",
      "-\n",
      "Input sentence: W J>MR >LJHM\n",
      "Decoded sentence: conjverbprep\n",
      "\n",
      "-\n",
      "Input sentence: <BRJ >NKJ\n",
      "Decoded sentence: verbprps\n",
      "\n",
      "-\n",
      "Input sentence: W >T JHWH >LHJ H CMJM >NJ JR>\n",
      "Decoded sentence: conjprepnmprverbartsubsprepnmpr\n",
      "\n",
      "-\n",
      "Input sentence: >CR <FH >T H JM W >T H JBCH\n",
      "Decoded sentence: conjverbprepartsubsconjprepartsubs\n",
      "\n",
      "-\n",
      "Input sentence: W JJR>W H >NCJM JR>H GDWLH\n",
      "Decoded sentence: conjverbartsubssubsadjv\n",
      "\n",
      "-\n",
      "Input sentence: W J>MRW >LJW\n",
      "Decoded sentence: conjverbprep\n",
      "\n",
      "-\n",
      "Input sentence: MH Z>T <FJT\n",
      "Decoded sentence: prinprdeverb\n",
      "\n",
      "-\n",
      "Input sentence: KJ JD<W H >NCJM\n",
      "Decoded sentence: conjverbartsubs\n",
      "\n",
      "-\n",
      "Input sentence: KJ M L PNJ JHWH HW> BRX\n",
      "Decoded sentence: conjprepprepsubsnmprprpsverb\n",
      "\n",
      "-\n",
      "Input sentence: KJ HGJD LHM\n",
      "Decoded sentence: conjverbprep\n",
      "\n",
      "-\n",
      "Input sentence: W J>MRW >LJW\n",
      "Decoded sentence: conjverbprep\n",
      "\n",
      "-\n",
      "Input sentence: MH N<FH LK\n",
      "Decoded sentence: prinverbprep\n",
      "\n",
      "-\n",
      "Input sentence: W JCTQ H JM M <LJNW\n",
      "Decoded sentence: conjverbartsubsprepprep\n",
      "\n",
      "-\n",
      "Input sentence: KJ H JM HWLK\n",
      "Decoded sentence: conjartsubsverb\n",
      "\n",
      "-\n",
      "Input sentence: W S<R\n",
      "Decoded sentence: conjverb\n",
      "\n",
      "-\n",
      "Input sentence: W J>MR >LJHM\n",
      "Decoded sentence: conjverbprep\n",
      "\n",
      "-\n",
      "Input sentence: F>WNJ\n",
      "Decoded sentence: verb\n",
      "\n",
      "-\n",
      "Input sentence: W HVJLNJ >L H JM\n",
      "Decoded sentence: conjverbprepartsubs\n",
      "\n",
      "-\n",
      "Input sentence: W JCTQ H JM M <LJKM\n",
      "Decoded sentence: conjverbartsubsprepprep\n",
      "\n",
      "-\n",
      "Input sentence: KJ JWD< >NJ\n",
      "Decoded sentence: conjadjvprps\n",
      "\n",
      "-\n",
      "Input sentence: W JXTRW H >NCJM\n",
      "Decoded sentence: conjverbartsubs\n",
      "\n",
      "-\n",
      "Input sentence: L HCJB >L H JBCH\n",
      "Decoded sentence: prepverbprepartsubs\n",
      "\n",
      "-\n",
      "Input sentence: W L> JKLW\n",
      "Decoded sentence: conjnegaverb\n",
      "\n",
      "-\n",
      "Input sentence: KJ H JM HWLK\n",
      "Decoded sentence: conjartsubsverb\n",
      "\n",
      "-\n",
      "Input sentence: W S<R <LJHM\n",
      "Decoded sentence: conjverbprep\n",
      "\n",
      "-\n",
      "Input sentence: W JQR>W >L JHWH\n",
      "Decoded sentence: conjverbprepnmpr\n",
      "\n",
      "-\n",
      "Input sentence: W J>MRW\n",
      "Decoded sentence: conjverb\n",
      "\n",
      "-\n",
      "Input sentence: >NH JHWH\n",
      "Decoded sentence: prpsnmpr\n",
      "\n",
      "-\n",
      "Input sentence: >L N> N>BDH B NPC H >JC H ZH\n",
      "Decoded sentence: prdenegaverbprepsubsartsubsartprde\n",
      "\n",
      "-\n",
      "Input sentence: W >L TTN <LJNW DM NQJ>\n",
      "Decoded sentence: conjnegaverbprepsubsnmpr\n",
      "\n",
      "-\n",
      "Input sentence: KJ >TH <FJT\n",
      "Decoded sentence: conjprpsverb\n",
      "\n",
      "-\n",
      "Input sentence: JHWH\n",
      "Decoded sentence: nmpr\n",
      "\n",
      "-\n",
      "Input sentence: K >CR XPYT\n",
      "Decoded sentence: prepconjverb\n",
      "\n",
      "-\n",
      "Input sentence: W JF>W >T JWNH\n",
      "Decoded sentence: conjverbprepnmpr\n",
      "\n",
      "-\n",
      "Input sentence: W JVLHW >L H JM\n",
      "Decoded sentence: conjverbprepartsubs\n",
      "\n",
      "-\n",
      "Input sentence: W J<MD H JM M Z<PW\n",
      "Decoded sentence: conjverbartsubsprepsubs\n",
      "\n",
      "-\n",
      "Input sentence: W JJR>W H >NCJM JR>H GDWLH >T JHWH\n",
      "Decoded sentence: conjverbartsubsnmprnmprprepnmpr\n",
      "\n",
      "-\n",
      "Input sentence: W JZBXW ZBX L JHWH\n",
      "Decoded sentence: conjverbsubsprepnmpr\n",
      "\n",
      "-\n",
      "Input sentence: W JDRW NDRJM\n",
      "Decoded sentence: conjverbsubs\n",
      "\n",
      "-\n",
      "Input sentence: W JMN JHWH DG GDWL\n",
      "Decoded sentence: conjverbnmprsubsnmpr\n",
      "\n",
      "-\n",
      "Input sentence: L BL< >T JWNH\n",
      "Decoded sentence: prepverbprepnmpr\n",
      "\n",
      "-\n",
      "Input sentence: W JTPLL JWNH >L JHWH >LHJW M M<J H DGH\n",
      "Decoded sentence: conjverbnmprprepnmprsubsprepprepartsubs\n",
      "\n",
      "-\n",
      "Input sentence: W J>MR\n",
      "Decoded sentence: conjverb\n",
      "\n",
      "-\n",
      "Input sentence: QR>TJ M YRH LJ >L JHWH\n",
      "Decoded sentence: verbprepsubsprepprepnmpr\n",
      "\n",
      "-\n",
      "Input sentence: W J<NNJ\n",
      "Decoded sentence: conjverb\n",
      "\n",
      "-\n",
      "Input sentence: M BVN C>WL CW<TJ\n",
      "Decoded sentence: prepsubsnmprsubs\n",
      "\n",
      "-\n",
      "Input sentence: CM<T QWLJ\n",
      "Decoded sentence: verbsubs\n",
      "\n",
      "-\n",
      "Input sentence: W TCLJKNJ MYWLH B LBB JMJM\n",
      "Decoded sentence: conjverbsubsprepsubssubs\n",
      "\n",
      "-\n",
      "Input sentence: W NHR JSBBNJ\n",
      "Decoded sentence: conjverbverb\n",
      "\n",
      "-\n",
      "Input sentence: KL MCBRJK W GLJK <LJ <BRW\n",
      "Decoded sentence: subssubsconjsubsprepverb\n",
      "\n",
      "-\n",
      "Input sentence: W >NJ >MRTJ\n",
      "Decoded sentence: conjprpsverb\n",
      "\n",
      "-\n",
      "Input sentence: NGRCTJ M NGD <JNJK\n",
      "Decoded sentence: verbprepsubssubs\n",
      "\n",
      "-\n",
      "Input sentence: >K >WSJP\n",
      "Decoded sentence: advbverb\n",
      "\n",
      "-\n",
      "Input sentence: L HBJV >L HJKL QDCK\n",
      "Decoded sentence: prepverbprepnmprsubs\n",
      "\n",
      "-\n",
      "Input sentence: >PPWNJ MJM <D NPC\n",
      "Decoded sentence: verbsubsprepprep\n",
      "\n",
      "-\n",
      "Input sentence: THWM JSBBNJ\n",
      "Decoded sentence: verbverb\n",
      "\n",
      "-\n",
      "Input sentence: SWP XBWC L R>CJ\n",
      "Decoded sentence: verbsubsprepsubs\n",
      "\n",
      "-\n",
      "Input sentence: L QYBJ HRJM JRDTJ\n",
      "Decoded sentence: prepsubsverbverb\n",
      "\n",
      "-\n",
      "Input sentence: H >RY\n",
      "Decoded sentence: artsubs\n",
      "\n",
      "-\n",
      "Input sentence: BRXJH B<DJ L <WLM\n",
      "Decoded sentence: verbsubsprepsubs\n",
      "\n",
      "-\n",
      "Input sentence: W T<L M CXT XJJ\n",
      "Decoded sentence: conjverbprepsubssubs\n",
      "\n",
      "-\n",
      "Input sentence: JHWH >LHJ\n",
      "Decoded sentence: nmprsubs\n",
      "\n",
      "-\n",
      "Input sentence: B HT<VP <LJ NPCJ\n",
      "Decoded sentence: prepverbprepsubs\n",
      "\n",
      "-\n",
      "Input sentence: >T JHWH ZKRTJ\n",
      "Decoded sentence: prepnmprverb\n",
      "\n",
      "-\n",
      "Input sentence: W TBW> >LJK TPLTJ >L HJKL QDCK\n",
      "Decoded sentence: conjverbprepsubsprepnmprsubs\n",
      "\n",
      "-\n",
      "Input sentence: MCMRJM HBLJ CW>\n",
      "Decoded sentence: verbverbadvb\n",
      "\n",
      "-\n",
      "Input sentence: XSDM J<ZBW\n",
      "Decoded sentence: subsverb\n",
      "\n",
      "-\n",
      "Input sentence: W >NJ\n",
      "Decoded sentence: conjprps\n",
      "\n",
      "-\n",
      "Input sentence: B QWL TWDH >ZBXH LK\n",
      "Decoded sentence: prepsubsverbverbprep\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: >CR NDRTJ\n",
      "Decoded sentence: conjverb\n",
      "\n",
      "-\n",
      "Input sentence: >CLMH\n",
      "Decoded sentence: subs\n",
      "\n",
      "-\n",
      "Input sentence: JCW<TH L JHWH\n",
      "Decoded sentence: verbprepnmpr\n",
      "\n",
      "-\n",
      "Input sentence: W J>MR JHWH L  DG\n",
      "Decoded sentence: conjverbnmprprepartsubs\n",
      "\n",
      "-\n",
      "Input sentence: W JQ> >T JWNH >L H JBCH\n",
      "Decoded sentence: conjverbprepnmprprepartnmpr\n",
      "\n",
      "-\n",
      "Input sentence: W JHJ DBR JHWH >L JWNH CNJT\n",
      "Decoded sentence: conjverbsubsnmprprepsubssubs\n",
      "\n",
      "-\n",
      "Input sentence: L >MR\n",
      "Decoded sentence: prepverb\n",
      "\n",
      "-\n",
      "Input sentence: QWM\n",
      "Decoded sentence: verb\n",
      "\n",
      "-\n",
      "Input sentence: LK >L NJNWH H <JR H GDWLH\n",
      "Decoded sentence: verbprepsubsartsubsartsubs\n",
      "\n",
      "-\n",
      "Input sentence: W QR> >LJH >T H QRJ>H\n",
      "Decoded sentence: conjverbprepprepartsubs\n",
      "\n",
      "-\n",
      "Input sentence: >CR >NKJ DBR >LJK\n",
      "Decoded sentence: conjprpsverbprep\n",
      "\n",
      "-\n",
      "Input sentence: W JQM JWNH\n",
      "Decoded sentence: conjverbnmpr\n",
      "\n",
      "-\n",
      "Input sentence: W JLK >L NJNWH K DBR JHWH\n",
      "Decoded sentence: conjverbprepnmprprepsubsnmpr\n",
      "\n",
      "-\n",
      "Input sentence: W NJNWH HJTH <JR GDWLH L >LHJM\n",
      "Decoded sentence: conjnmprverbsubssubsprepsubs\n",
      "\n",
      "-\n",
      "Input sentence: MHLK CLCT JMJM\n",
      "Decoded sentence: verbsubssubs\n",
      "\n",
      "-\n",
      "Input sentence: W JXL JWNH\n",
      "Decoded sentence: conjverbnmpr\n",
      "\n",
      "-\n",
      "Input sentence: L BW> B  <JR MHLK JWM >XD\n",
      "Decoded sentence: prepverbprepartsubssubssubssubs\n",
      "\n",
      "-\n",
      "Input sentence: W JQR>\n",
      "Decoded sentence: conjverb\n",
      "\n",
      "-\n",
      "Input sentence: W J>MR\n",
      "Decoded sentence: conjverb\n",
      "\n",
      "-\n",
      "Input sentence: <WD >RB<JM JWM\n",
      "Decoded sentence: subssubssubs\n",
      "\n",
      "-\n",
      "Input sentence: W NJNWH NHPKT\n",
      "Decoded sentence: conjnmprverb\n",
      "\n",
      "-\n",
      "Input sentence: W J>MJNW >NCJ NJNWH B >LHJM\n",
      "Decoded sentence: conjverbsubssubsprepsubs\n",
      "\n",
      "-\n",
      "Input sentence: W JQR>W YWM\n",
      "Decoded sentence: conjverbsubs\n",
      "\n",
      "-\n",
      "Input sentence: W JLBCW FQJM M GDWLM W <D QVNM\n",
      "Decoded sentence: conjverbnmprprepsubsconjprepsubs\n",
      "\n",
      "-\n",
      "Input sentence: W JG< H DBR >L MLK NJNWH\n",
      "Decoded sentence: conjverbartsubsprepsubsnmpr\n",
      "\n",
      "-\n",
      "Input sentence: W JQM M KS>W\n",
      "Decoded sentence: conjverbprepsubs\n",
      "\n",
      "-\n",
      "Input sentence: W J<BR >DRTW M <LJW\n",
      "Decoded sentence: conjverbsubsprepprep\n",
      "\n",
      "-\n",
      "Input sentence: W JKS FQ\n",
      "Decoded sentence: conjverbnmpr\n",
      "\n",
      "-\n",
      "Input sentence: W JCB <L H >PR\n",
      "Decoded sentence: conjverbprepartsubs\n",
      "\n",
      "-\n",
      "Input sentence: W JZ<Q\n",
      "Decoded sentence: conjverb\n",
      "\n",
      "-\n",
      "Input sentence: W J>MR\n",
      "Decoded sentence: conjverb\n",
      "\n",
      "-\n",
      "Input sentence: B NJNWH M V<M H MLK W GDLJW\n",
      "Decoded sentence: prepverbprepsubsartsubsprepsubs\n",
      "\n",
      "-\n",
      "Input sentence: L >MR\n",
      "Decoded sentence: prepverb\n",
      "\n",
      "-\n",
      "Input sentence: >L JR<W\n",
      "Decoded sentence: negaverb\n",
      "\n",
      "-\n",
      "Input sentence: W MJM >L JCTW\n",
      "Decoded sentence: conjsubsprepverb\n",
      "\n",
      "-\n",
      "Input sentence: W JTKSW FQJM H >DM W H BHMH\n",
      "Decoded sentence: conjverbnmprartsubsartprpsartsubs\n",
      "\n",
      "-\n",
      "Input sentence: W JQR>W >L >LHJM B XZQH\n",
      "Decoded sentence: conjverbprepsubsprepnmpr\n",
      "\n",
      "-\n",
      "Input sentence: W JCBW\n",
      "Decoded sentence: conjverb\n",
      "\n",
      "-\n",
      "Input sentence: >JC M DRKW H R<H W MN H XMS\n",
      "Decoded sentence: subsprepsubsartsubsconjsubsartsubs\n",
      "\n",
      "-\n",
      "Input sentence: >CR B KPJHM\n",
      "Decoded sentence: conjprepsubs\n",
      "\n",
      "-\n",
      "Input sentence: MJ JWD<\n",
      "Decoded sentence: prinverb\n",
      "\n",
      "-\n",
      "Input sentence: JCWB\n",
      "Decoded sentence: verb\n",
      "\n",
      "-\n",
      "Input sentence: W NXM H >LHJM\n",
      "Decoded sentence: conjverbartsubs\n",
      "\n",
      "-\n",
      "Input sentence: W CB M XRWN >PW\n",
      "Decoded sentence: conjverbprepsubssubs\n",
      "\n",
      "-\n",
      "Input sentence: W L> N>BD\n",
      "Decoded sentence: conjnegaverb\n",
      "\n",
      "-\n",
      "Input sentence: W JR> H >LHJM >T M<FJHM\n",
      "Decoded sentence: conjverbartsubsprepsubs\n",
      "\n",
      "-\n",
      "Input sentence: KJ CBW M DRKM H R<H\n",
      "Decoded sentence: conjverbprepsubsartsubs\n",
      "\n",
      "-\n",
      "Input sentence: W JNXM H >LHJM <L H R<H\n",
      "Decoded sentence: conjverbartsubsprepartsubs\n",
      "\n",
      "-\n",
      "Input sentence: >CR DBR\n",
      "Decoded sentence: conjverb\n",
      "\n",
      "-\n",
      "Input sentence: L <FWT LHM\n",
      "Decoded sentence: prepverbprep\n",
      "\n",
      "-\n",
      "Input sentence: W L> <FH\n",
      "Decoded sentence: conjnegaverb\n",
      "\n",
      "-\n",
      "Input sentence: W JR< >L JWNH R<H GDWLH\n",
      "Decoded sentence: conjverbprepnmprsubsnmpr\n",
      "\n",
      "-\n",
      "Input sentence: W JXR LW\n",
      "Decoded sentence: conjverbprep\n",
      "\n",
      "-\n",
      "Input sentence: W JTPLL >L JHWH\n",
      "Decoded sentence: conjverbprepnmpr\n",
      "\n",
      "-\n",
      "Input sentence: W J>MR\n",
      "Decoded sentence: conjverb\n",
      "\n",
      "-\n",
      "Input sentence: >NH JHWH\n",
      "Decoded sentence: prpsnmpr\n",
      "\n",
      "-\n",
      "Input sentence: H LW> ZH DBRJ\n",
      "Decoded sentence: inrgnegaadvbverb\n",
      "\n",
      "-\n",
      "Input sentence: <D HJWTJ <L >DMTJ\n",
      "Decoded sentence: prepverbprepsubs\n",
      "\n",
      "-\n",
      "Input sentence: <L KN QDMTJ\n",
      "Decoded sentence: prepadvbverb\n",
      "\n",
      "-\n",
      "Input sentence: L BRX TRCJCH\n",
      "Decoded sentence: prepverbsubs\n",
      "\n",
      "-\n",
      "Input sentence: KJ JD<TJ\n",
      "Decoded sentence: conjverb\n",
      "\n",
      "-\n",
      "Input sentence: KJ >TH >L XNWN W RXWM\n",
      "Decoded sentence: conjprpsprepnmprconjsubs\n",
      "\n",
      "-\n",
      "Input sentence: >RK >PJM\n",
      "Decoded sentence: subsadjv\n",
      "\n",
      "-\n",
      "Input sentence: W RB XSD\n",
      "Decoded sentence: conjsubssubs\n",
      "\n",
      "-\n",
      "Input sentence: W NXM <L H R<H\n",
      "Decoded sentence: conjverbprepartsubs\n",
      "\n",
      "-\n",
      "Input sentence: W <TH\n",
      "Decoded sentence: conjadvb\n",
      "\n",
      "-\n",
      "Input sentence: JHWH\n",
      "Decoded sentence: nmpr\n",
      "\n",
      "-\n",
      "Input sentence: QX N> >T NPCJ MMNJ\n",
      "Decoded sentence: verbintjprepsubsprep\n",
      "\n",
      "-\n",
      "Input sentence: KJ VWB MWTJ M XJJ\n",
      "Decoded sentence: conjverbsubsprepsubs\n",
      "\n",
      "-\n",
      "Input sentence: W J>MR JHWH\n",
      "Decoded sentence: conjverbnmpr\n",
      "\n",
      "-\n",
      "Input sentence: H HJVB\n",
      "Decoded sentence: artverb\n",
      "\n",
      "-\n",
      "Input sentence: XRH LK\n",
      "Decoded sentence: verbprep\n",
      "\n",
      "-\n",
      "Input sentence: W JY> JWNH MN H <JR\n",
      "Decoded sentence: conjverbsubsprepartsubs\n",
      "\n",
      "-\n",
      "Input sentence: W JCB M QDM L  <JR\n",
      "Decoded sentence: conjverbprepsubsprepartsubs\n",
      "\n",
      "-\n",
      "Input sentence: W J<F LW CM SKH\n",
      "Decoded sentence: conjverbprepsubsnmpr\n",
      "\n",
      "-\n",
      "Input sentence: W JCB TXTJH B  YL\n",
      "Decoded sentence: conjverbsubsprepartsubs\n",
      "\n",
      "-\n",
      "Input sentence: <D >CR JR>H\n",
      "Decoded sentence: prepconjverb\n",
      "\n",
      "-\n",
      "Input sentence: MH JHJH B  <JR\n",
      "Decoded sentence: prinverbprepartsubs\n",
      "\n",
      "-\n",
      "Input sentence: W JMN JHWH >LHJM QJQJWN\n",
      "Decoded sentence: conjverbnmprsubsnmpr\n",
      "\n",
      "-\n",
      "Input sentence: W J<L M <L L JWNH\n",
      "Decoded sentence: conjverbprepprepprepnmpr\n",
      "\n",
      "-\n",
      "Input sentence: L HJWT YL <L R>CW\n",
      "Decoded sentence: prepverbsubsprepsubs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(200):\n",
    "    inp_seq = tokenized_test_data[seq_index:seq_index+1]\n",
    "    \n",
    "    translated_sent = decode_seq(inp_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', test_clauses[seq_index])\n",
    "    print('Decoded sentence:', translated_sent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
