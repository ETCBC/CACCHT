{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find phrase boundaries in BH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model in this notebook is designed to find phrase boundaries in chunks of BH text, based on the division in phrases in the ETCBC database.\n",
    "The model assumes that the text has been analyzed on word level already.\n",
    "\n",
    "Each input chunk consists of 20 words. Each word is represented by its part of speech. For instance, a typical chunk has the following structure (the example shows the first 20 words of the book of Genesis):\n",
    "\n",
    "['prep', 'subs', 'verb', 'subs', 'prep', 'art', 'subs', 'conj', 'prep', 'art', 'subs', 'conj', 'art', 'subs', 'verb', 'subs',  'conj',  'subs','conj', 'subs']\n",
    "\n",
    "The corresponding output is:\n",
    "\n",
    "['\\t', 'x', 'x', 'p', 'x', 'p', 'x', 'p', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'p', 'x', 'p', 'x', 'x', 'p', 'x', 'p', 'x', 'x', 'x', 'p', 'x', 'p', 'x', 'p', '\\n']\n",
    "\n",
    "Here every 'x' represents a word in the input sequence, and 'p' marks the end of a phrase. '\\t' and '\\n' are start and stop symbols. \n",
    "\n",
    "In the following input chunk we have moved forward one word:\n",
    "\n",
    "Input:\n",
    "\n",
    " ['subs', 'verb', 'subs', 'prep', 'art', 'subs', 'conj', 'prep', 'art', 'subs', 'conj', 'art', 'subs', 'verb', 'subs', 'conj', 'subs', 'conj', 'subs', 'prep']\n",
    "\n",
    "Output:\n",
    "\n",
    "['\\t', 'x', 'p', 'x', 'p', 'x', 'p', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'p', 'x', 'p', 'x', 'x', 'p', 'x', 'p', 'x', 'x', 'x', 'p', 'x', 'p', 'x', 'p', 'x', '\\n']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geitb\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF app is up-to-date.\n",
      "Using annotation/app-bhsa commit 7f353d587f4befb6efe1742831e28f301d2b3cea (=latest)\n",
      "  in C:\\Users\\geitb/text-fabric-data/__apps__/bhsa.\n",
      "Using etcbc/bhsa/tf - c r1.5 in C:\\Users\\geitb/text-fabric-data\n",
      "Using etcbc/phono/tf - c r1.2 in C:\\Users\\geitb/text-fabric-data\n",
      "Using etcbc/parallels/tf - c r1.2 in C:\\Users\\geitb/text-fabric-data\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Documentation:** <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa\" title=\"provenance of BHSA = Biblia Hebraica Stuttgartensia Amstelodamensis\">BHSA</a> <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Writing/Hebrew\" title=\"('Hebrew characters and transcriptions',)\">Character table</a> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/0_home.html\" title=\"BHSA feature documentation\">Feature docs</a> <a target=\"_blank\" href=\"https://github.com/annotation/app-bhsa\" title=\"bhsa API documentation\">bhsa API</a> <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Fabric/\" title=\"text-fabric-api\">Text-Fabric API 7.3.15</a> <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Use/Search/\" title=\"Search Templates Introduction and Reference\">Search Reference</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<details open><summary><b>Loaded features</b>:</summary>\n",
       "<p><b>BHSA = Biblia Hebraica Stuttgartensia Amstelodamensis</b>: <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/book.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\book.tf\">book</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/book@ll.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\book@am.tf\">book@ll</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/chapter.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\chapter.tf\">chapter</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/code.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\code.tf\">code</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/det.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\det.tf\">det</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/freq_lex.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\freq_lex.tf\">freq_lex</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/function.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\function.tf\">function</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/g_word.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\g_word.tf\">g_word</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/g_word_utf8.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\g_word_utf8.tf\">g_word_utf8</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/gloss.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\gloss.tf\">gloss</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/gn.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\gn.tf\">gn</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/label.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\label.tf\">label</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/language.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\language.tf\">language</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/lex.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\lex.tf\">lex</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/lex_utf8.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\lex_utf8.tf\">lex_utf8</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/ls.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\ls.tf\">ls</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/nametype.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\nametype.tf\">nametype</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/nu.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\nu.tf\">nu</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/number.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\number.tf\">number</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/otype.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\otype.tf\">otype</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/pdp.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\pdp.tf\">pdp</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/prs_gn.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\prs_gn.tf\">prs_gn</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/prs_nu.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\prs_nu.tf\">prs_nu</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/prs_ps.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\prs_ps.tf\">prs_ps</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/ps.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\ps.tf\">ps</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/qere.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\qere.tf\">qere</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/qere_trailer.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\qere_trailer.tf\">qere_trailer</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/qere_trailer_utf8.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\qere_trailer_utf8.tf\">qere_trailer_utf8</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/qere_utf8.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\qere_utf8.tf\">qere_utf8</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/rank_lex.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\rank_lex.tf\">rank_lex</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/rela.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\rela.tf\">rela</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/sp.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\sp.tf\">sp</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/st.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\st.tf\">st</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/trailer.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\trailer.tf\">trailer</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/trailer_utf8.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\trailer_utf8.tf\">trailer_utf8</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/txt.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\txt.tf\">txt</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/typ.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\typ.tf\">typ</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/verse.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\verse.tf\">verse</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/voc_lex.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\voc_lex.tf\">voc_lex</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/voc_lex_utf8.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\voc_lex_utf8.tf\">voc_lex_utf8</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/vs.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\vs.tf\">vs</a>  <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/vt.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\vt.tf\">vt</a>  <b><i><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/mother.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\mother.tf\">mother</a></i></b>  <b><i><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/hebrew/c/oslots.html\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/bhsa/tf/c\\oslots.tf\">oslots</a></i></b> </p><p><b>Parallel Passages</b>: <b><i><a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/etcbc/parallels/blob/master/programs/parallels.ipynb\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/parallels/tf/c\\crossref.tf\">crossref</a></i></b> </p><p><b>Phonetic Transcriptions</b>: <a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/etcbc/phono/blob/master/programs/phono.ipynb\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/phono/tf/c\\phono.tf\">phono</a>  <a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/etcbc/phono/blob/master/programs/phono.ipynb\" title=\"C:\\Users\\geitb/text-fabric-data/etcbc/phono/tf/c\\phono_trailer.tf\">phono_trailer</a> </p></details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@font-face {\n",
       "  font-family: \"Ezra SIL\";\n",
       "  src: url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SILEOT.ttf?raw=true');\n",
       "  src: url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SILEOT.woff?raw=true') format('woff');\n",
       "}\n",
       ".features {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0a6611;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    direction: ltr;\n",
       "}\n",
       ".features div,.features span {\n",
       "    padding: 0;\n",
       "    margin: -0.1rem 0;\n",
       "}\n",
       ".features .f {\n",
       "    font-family: sans-serif;\n",
       "    font-size: x-small;\n",
       "    font-weight: normal;\n",
       "    color: #5555bb;\n",
       "}\n",
       ".features .xft {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: medium;\n",
       "  margin: 0.1em 0em;\n",
       "}\n",
       ".features .xft .f {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-style: italic;\n",
       "  font-size: small;\n",
       "  font-weight: normal;\n",
       "}\n",
       ".ltr {\n",
       "    direction: ltr ! important;\n",
       "}\n",
       ".verse {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: rtl;\n",
       "}\n",
       ".vl {\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    justify-content: flex-end;\n",
       "    align-items: flex-end;\n",
       "    direction: ltr;\n",
       "    width: 100%;\n",
       "}\n",
       ".outeritem {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: rtl;\n",
       "}\n",
       ".sentence,.clause,.phrase {\n",
       "    margin-top: -1.2em;\n",
       "    margin-left: 1em;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding: 0 0.3em;\n",
       "    border-style: solid;\n",
       "    border-radius: 0.2em;\n",
       "    font-size: small;\n",
       "    display: block;\n",
       "    width: fit-content;\n",
       "    max-width: fit-content;\n",
       "    direction: ltr;\n",
       "}\n",
       ".atoms {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    margin: 0.3em;\n",
       "    padding: 0.3em;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".satom,.catom,.patom {\n",
       "    margin: 0.3em;\n",
       "    padding: 0.3em;\n",
       "    border-radius: 0.3em;\n",
       "    border-style: solid;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".sentence {\n",
       "    border-color: #aa3333;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".clause {\n",
       "    border-color: #aaaa33;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".phrase {\n",
       "    border-color: #33aaaa;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".satom {\n",
       "    border-color: #aa3333;\n",
       "    border-width: 4px;\n",
       "}\n",
       ".catom {\n",
       "    border-color: #aaaa33;\n",
       "    border-width: 3px;\n",
       "}\n",
       ".patom {\n",
       "    border-color: #33aaaa;\n",
       "    border-width: 3px;\n",
       "}\n",
       ".word {\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    border-radius: 0.1em;\n",
       "    border: 1px solid #cccccc;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".lextp {\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    border-radius: 0.1em;\n",
       "    border: 2px solid #888888;\n",
       "    width: fit-content;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".occs {\n",
       "    font-size: x-small;\n",
       "}\n",
       ".satom.l,.catom.l,.patom.l {\n",
       "    border-left-style: dotted\n",
       "}\n",
       ".satom.r,.catom.r,.patom.r {\n",
       "    border-right-style: dotted\n",
       "}\n",
       ".satom.lno,.catom.lno,.patom.lno {\n",
       "    border-left-style: none\n",
       "}\n",
       ".satom.rno,.catom.rno,.patom.rno {\n",
       "    border-right-style: none\n",
       "}\n",
       ".tr,.tr a:visited,.tr a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: large;\n",
       "    color: #000044;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".trb,.trb a:visited,.trb a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: normal;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".prb,.prb a:visited,.prb a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: large;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".h,.h a:visited,.h a:link {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    color: #000044;\n",
       "    direction: rtl;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".hb,.hb a:visited,.hb a:link {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    line-height: 2;\n",
       "    direction: rtl;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".vn {\n",
       "  font-size: small !important;\n",
       "  padding-right: 1em;\n",
       "}\n",
       ".rela,.function,.typ {\n",
       "    font-family: monospace;\n",
       "    font-size: small;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".pdp,.pdp a:visited,.pdp a:link {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    color: #0000bb;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".voc_lex {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".vs {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".vt {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".gloss {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: normal;\n",
       "    color: #444444;\n",
       "}\n",
       ".vrs {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: #444444;\n",
       "}\n",
       ".nd {\n",
       "    font-family: monospace;\n",
       "    font-size: x-small;\n",
       "    color: #999999;\n",
       "}\n",
       ".hl {\n",
       "    background-color: #ffee66;\n",
       "}\n",
       "span.hldot {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder: 0.2rem solid var(--hl-rim);\n",
       "\tborder-radius: 0.4rem;\n",
       "\t/*\n",
       "\tdisplay: inline-block;\n",
       "\twidth: 0.8rem;\n",
       "\theight: 0.8rem;\n",
       "\t*/\n",
       "}\n",
       "span.hl {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder-width: 0;\n",
       "\tborder-radius: 0.1rem;\n",
       "\tborder-style: solid;\n",
       "}\n",
       "\n",
       "span.hlup {\n",
       "\tborder-color: var(--hl-dark);\n",
       "\tborder-width: 0.1rem;\n",
       "\tborder-style: solid;\n",
       "\tborder-radius: 0.2rem;\n",
       "  padding: 0.2rem;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--hl-strong:        hsla( 60, 100%,  70%, 0.9  );\n",
       "\t--hl-rim:           hsla( 55, 100%,  60%, 0.9  );\n",
       "\t--hl-dark:          hsla( 55, 100%,  40%, 0.9  );\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<details open><summary><b>API members</b>:</summary>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Computed/#computed-data\" title=\"doc\">C Computed</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Computed/#computed-data\" title=\"doc\">Call AllComputeds</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Computed/#computed-data\" title=\"doc\">Cs ComputedString</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Features/#edge-features\" title=\"doc\">E Edge</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Features/#edge-features\" title=\"doc\">Eall AllEdges</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Features/#edge-features\" title=\"doc\">Es EdgeString</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Fabric/#loading\" title=\"doc\">ensureLoaded</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Fabric/#loading\" title=\"doc\">TF</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Fabric/#loading\" title=\"doc\">ignored</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Fabric/#loading\" title=\"doc\">loadLog</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Locality/#locality\" title=\"doc\">L Locality</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Misc/#messaging\" title=\"doc\">cache</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Misc/#messaging\" title=\"doc\">error</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Misc/#messaging\" title=\"doc\">indent</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Misc/#messaging\" title=\"doc\">info</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Misc/#messaging\" title=\"doc\">reset</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Nodes/#navigating-nodes\" title=\"doc\">N Nodes</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Nodes/#navigating-nodes\" title=\"doc\">sortKey</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Nodes/#navigating-nodes\" title=\"doc\">sortKeyTuple</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Nodes/#navigating-nodes\" title=\"doc\">otypeRank</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Nodes/#navigating-nodes\" title=\"doc\">sortNodes</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Features/#node-features\" title=\"doc\">F Feature</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Features/#node-features\" title=\"doc\">Fall AllFeatures</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Features/#node-features\" title=\"doc\">Fs FeatureString</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Search/#search\" title=\"doc\">S Search</a><br/>\n",
       "<a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/Api/Text/#text\" title=\"doc\">T Text</a></details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tf.app import use\n",
    "A = use('bhsa', hoist=globals())\n",
    "A.displaySetup(extraFeatures='g_cons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A train and test set are defined. The model is trained on all the books of the MT, except Jonah. The model will be used to predict parts of speech for this book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genesis\n",
      "Exodus\n",
      "Leviticus\n",
      "Numeri\n",
      "Deuteronomium\n",
      "Josua\n",
      "Judices\n",
      "Samuel_I\n",
      "Samuel_II\n",
      "Reges_I\n",
      "Reges_II\n",
      "Jesaia\n",
      "Jeremia\n",
      "Ezechiel\n",
      "Hosea\n",
      "Joel\n",
      "Amos\n",
      "Obadia\n",
      "Jona\n",
      "Micha\n",
      "Nahum\n",
      "Habakuk\n",
      "Zephania\n",
      "Haggai\n",
      "Sacharia\n",
      "Maleachi\n",
      "Psalmi\n",
      "Iob\n",
      "Proverbia\n",
      "Ruth\n",
      "Canticum\n",
      "Ecclesiastes\n",
      "Threni\n",
      "Esther\n",
      "Daniel\n",
      "Esra\n",
      "Nehemia\n",
      "Chronica_I\n",
      "Chronica_II\n"
     ]
    }
   ],
   "source": [
    "for bo in F.otype.s(\"book\"):\n",
    "    print(F.book.v(bo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are prepared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_data():\n",
    "    \"\"\"\"\n",
    "    books is a list containing the books of the training set.\n",
    "    The function returns:\n",
    "    input_clauses is a list containing strings with the text of BH clauses\n",
    "    output_pos is a list containing lists with all the pos of BH clauses\n",
    "    input_vocab is a list containing the characters occurring in the input_clauses (the input vocabulary)\n",
    "    output_vocab is a list containing all the pos occurring in the bhsa\n",
    "    max_len_input is the maximum length of all the input clauses in number of characters\n",
    "    max_len_output is the maximum length of all the output clauses in number of phrases (+2, because a \n",
    "    start and stop sign are added)\n",
    "    \"\"\"\n",
    "\n",
    "    input_clauses = []\n",
    "    output_phrases = []\n",
    "    input_vocab = set()\n",
    "    output_vocab = {'x', '\\t', '\\n', 'w'}\n",
    "\n",
    "    for bo in F.otype.s(\"book\"): \n",
    "\n",
    "        if F.book.v(bo) == \"Jona\":\n",
    "            continue\n",
    "        \n",
    "        words_in_book = L.d(bo, \"word\")\n",
    "        \n",
    "        for wo in range(words_in_book[0], words_in_book[-1] - 5):\n",
    "            #if F.trailer_utf8.v(wo) == '':\n",
    "            #    continue\n",
    "            if F.trailer_utf8.v(wo) != '' and F.trailer_utf8.v(wo-1) == '' and wo != words_in_book[0]:\n",
    "                continue\n",
    "            \n",
    "             \n",
    "            input_chunk = (\"\".join([\"\".join([F.g_cons.v(wo2), F.trailer_utf8.v(wo2)]) for wo2 in range(wo, wo+5)])).strip()\n",
    "            \n",
    "            all_words = [w for w in range(wo, wo+5)]\n",
    "            if F.trailer_utf8.v(wo+4) == '':\n",
    "                input_chunk += F.g_cons.v(wo+5)\n",
    "                all_words.append(wo+5)\n",
    "            if F.trailer_utf8.v(wo+4) == '' and F.trailer_utf8.v(wo+5) == '':\n",
    "                input_chunk += F.g_cons.v(wo+6)\n",
    "                all_words.append(wo+6)\n",
    "                \n",
    "            \n",
    "            for char in input_chunk:\n",
    "                input_vocab.add(char)\n",
    "            \n",
    "            output_prep = []\n",
    "            for word in sorted(all_words):\n",
    "                for char in F.g_cons.v(word):\n",
    "                    output_prep.append('x')\n",
    "                output_prep.append(\"w\")\n",
    "                        \n",
    "\n",
    "            output_chunk = ['\\t']\n",
    "            for elem in output_prep:\n",
    "                output_chunk.append(elem)\n",
    "            output_chunk.append('\\n')\n",
    "    \n",
    "            input_clauses.append(input_chunk)\n",
    "            output_phrases.append(output_chunk)\n",
    "    \n",
    "    input_chars = sorted(list(input_vocab))\n",
    "    output_vocab = sorted(list(output_vocab))\n",
    "    \n",
    "    max_len_input = max([len(clause) for clause in input_clauses])\n",
    "    max_len_output = max([len(output_phr) for output_phr in output_phrases])\n",
    "    \n",
    "    # shuffle the data\n",
    "    #input_clauses, output_phrases = shuffle(input_clauses, output_phrases)\n",
    "    \n",
    "    return input_clauses, output_phrases, input_vocab, output_vocab, max_len_input, max_len_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'', '׃ ', '׃ ׆ ', ' פ ', '׃ ׆ ס ', '׀ ', ' ', '׃ פ ', '׃ ׆ פ ', '־', ' ס ', '׃ ס '}\n"
     ]
    }
   ],
   "source": [
    "tr_set = set()\n",
    "for w in F.otype.s('word'):\n",
    "    tr_set.add(F.trailer_utf8.v(w))\n",
    "    \n",
    "print(tr_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([0,2,4,3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_data():\n",
    "    \"\"\"\n",
    "    books is a list containing the test books\n",
    "    The function returns:\n",
    "    input_clauses, a list containing the text of clauses in the test books\n",
    "    \"\"\"\n",
    "    input_clauses_test = []\n",
    "    outputs_test = []\n",
    "    for bo in F.otype.s(\"book\"): \n",
    "\n",
    "        if F.book.v(bo) != \"Jona\":\n",
    "            continue\n",
    "        \n",
    "        words_in_book = L.d(bo, \"word\")\n",
    "        \n",
    "        for wo in range(words_in_book[0], words_in_book[-1] - 5):\n",
    "            \n",
    "            if F.trailer_utf8.v(wo) != '' and F.trailer_utf8.v(wo-1) == '' and wo != words_in_book[0]:\n",
    "                continue\n",
    "            \n",
    "            input_chunk = (\"\".join([\"\".join([F.g_cons.v(wo2), F.trailer_utf8.v(wo2)]) for wo2 in range(wo, wo+5)])).strip()\n",
    "            \n",
    "            all_words = [w for w in range(wo, wo+5)]\n",
    "            if F.trailer_utf8.v(wo+4) == '':\n",
    "                input_chunk += F.g_cons.v(wo+5)\n",
    "                all_words.append(wo+5)\n",
    "            if F.trailer_utf8.v(wo+4) == '' and F.trailer_utf8.v(wo+5) == '':\n",
    "                input_chunk += F.g_cons.v(wo+6)\n",
    "                all_words.append(wo+6)\n",
    "                \n",
    "            input_clauses_test.append(input_chunk)\n",
    "            \n",
    "            output_chunk = []\n",
    "            for w in all_words:\n",
    "                for ch in F.g_cons.v(w):\n",
    "                    output_chunk.append('x')\n",
    "                output_chunk.append('w')\n",
    "            outputs_test.append(output_chunk)\n",
    "    \n",
    "    return input_clauses_test, outputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dicts(input_vocab, output_vocab):\n",
    "    \"\"\"\n",
    "    The network can only handle numeric data. This function provides four dicts. \n",
    "    Two of them map between integers and the input characters (one dict for every direction), the other two \n",
    "    map between integers and parts of speech.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    input_idx2char = {}\n",
    "    input_char2idx = {}\n",
    "\n",
    "    for k, v in enumerate(input_chars):\n",
    "        input_idx2char[k] = v\n",
    "        input_char2idx[v] = k\n",
    "        \n",
    "    output_idx2char = {}\n",
    "    output_char2idx = {}\n",
    "    \n",
    "    for k, v in enumerate(output_vocab):\n",
    "        output_idx2char[k] = v\n",
    "        output_char2idx[v] = k\n",
    "     \n",
    "    \n",
    "    return input_idx2char, input_char2idx, output_idx2char, output_char2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(nb_samples, max_len_input, max_len_output, input_chars, output_vocab, input_char2idx, output_char2idx, input_clauses, output_pos):\n",
    "    \"\"\"\n",
    "    Categorical data are generally one-hot encoded in neural networks, which is done here.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    tokenized_input_data = np.zeros(shape = (nb_samples,max_len_input,len(input_chars)), dtype='float32')\n",
    "    tokenized_output = np.zeros(shape = (nb_samples,max_len_output,len(output_vocab)), dtype='float32')\n",
    "    target_data = np.zeros((nb_samples, max_len_output, len(output_vocab)),dtype='float32')\n",
    "\n",
    "    for i in range(nb_samples):\n",
    "        for k, ch in enumerate(input_clauses[i]):\n",
    "            tokenized_input_data[i, k, input_char2idx[ch]] = 1\n",
    "        \n",
    "        for k, ch in enumerate(output_pos[i]):\n",
    "            tokenized_output[i, k, output_char2idx[ch]] = 1\n",
    "\n",
    "            # decoder_target_data will be ahead by one timestep and will not include the start character.\n",
    "            if k > 0:\n",
    "                target_data[i, k-1, output_char2idx[ch]] = 1\n",
    "                \n",
    "    return tokenized_input_data, tokenized_output, target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_LSTM_model(input_chars, output_vocab):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Encoder model\n",
    "\n",
    "    encoder_input = Input(shape=(None,len(input_chars)))\n",
    "    encoder_LSTM = LSTM(512,activation = 'relu',return_state = True, return_sequences=True)(encoder_input)\n",
    "    encoder_LSTM = LSTM(512,return_state = True)(encoder_LSTM)\n",
    "    encoder_outputs, encoder_h, encoder_c = encoder_LSTM\n",
    "    encoder_states = [encoder_h, encoder_c]\n",
    "    \n",
    "    # Decoder model\n",
    "\n",
    "    decoder_input = Input(shape=(None,len(output_vocab)))\n",
    "    decoder_LSTM = LSTM(512, return_sequences=True, return_state = True)\n",
    "    decoder_out, _ , _ = decoder_LSTM(decoder_input, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(len(output_vocab), activation='softmax')\n",
    "    decoder_out = decoder_dense (decoder_out)\n",
    "    \n",
    "    model = Model(inputs=[encoder_input, decoder_input],outputs=[decoder_out])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return encoder_input, encoder_states, decoder_input, decoder_LSTM, decoder_dense, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_train(model, tokenized_input, tokenized_output, batch_size, epochs, validation_split):\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "    model.fit(x=[tokenized_input,tokenized_output], \n",
    "              y=target_data,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_split=validation_split)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples = 300000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_clauses, output_pos, input_chars, output_vocab, max_len_input, max_len_output = prepare_train_data()\n",
    "input_idx2char, input_char2idx, output_idx2char, output_char2idx = create_dicts(input_chars, output_vocab)\n",
    "tokenized_input, tokenized_output, target_data = one_hot_encode(nb_samples, max_len_input, max_len_output, input_chars, output_vocab, input_char2idx, output_char2idx, input_clauses, output_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315697"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_clauses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WJHJ DBR־JHWH >L־\n",
      "DBR־JHWH >L־JWNH BN־\n",
      "JHWH >L־JWNH BN־>MTJ\n",
      ">L־JWNH BN־>MTJ L\n",
      "JWNH BN־>MTJ L>MR׃\n",
      "BN־>MTJ L>MR׃ QWM\n",
      ">MTJ L>MR׃ QWM LK\n",
      "L>MR׃ QWM LK >L־\n",
      "QWM LK >L־NJNWH H\n",
      "LK >L־NJNWH H<JR\n",
      ">L־NJNWH H<JR H\n",
      "NJNWH H<JR HGDWLH\n",
      "H<JR HGDWLH W\n",
      "HGDWLH WQR> <LJH\n",
      "WQR> <LJH KJ־<LTH\n",
      "<LJH KJ־<LTH R<TM L\n",
      "KJ־<LTH R<TM LPNJ׃\n",
      "<LTH R<TM LPNJ׃ W\n",
      "R<TM LPNJ׃ WJQM\n",
      "LPNJ׃ WJQM JWNH\n",
      "WJQM JWNH LBRX\n",
      "JWNH LBRX TRCJCH M\n",
      "LBRX TRCJCH ML\n",
      "TRCJCH MLPNJ JHWH\n",
      "MLPNJ JHWH W\n",
      "LPNJ JHWH WJRD\n",
      "JHWH WJRD JPW W\n",
      "WJRD JPW WJMY>\n",
      "JPW WJMY> >NJH׀ B>H\n",
      "WJMY> >NJH׀ B>H TRCJC\n",
      ">NJH׀ B>H TRCJC WJTN\n",
      "B>H TRCJC WJTN FKRH\n",
      "TRCJC WJTN FKRH W\n",
      "WJTN FKRH WJRD\n",
      "FKRH WJRD BH L\n",
      "WJRD BH LBW>\n",
      "BH LBW> <MHM TRCJCH\n",
      "LBW> <MHM TRCJCH M\n",
      "<MHM TRCJCH MLPNJ\n",
      "TRCJCH MLPNJ JHWH׃\n",
      "MLPNJ JHWH׃ W\n",
      "LPNJ JHWH׃ WJHWH\n",
      "JHWH׃ WJHWH HVJL RWX־\n",
      "WJHWH HVJL RWX־GDWLH\n",
      "HVJL RWX־GDWLH >L־H\n",
      "RWX־GDWLH >L־HJM\n",
      "GDWLH >L־HJM W\n",
      ">L־HJM WJHJ\n",
      "HJM WJHJ S<R־\n",
      "WJHJ S<R־GDWL B\n",
      "S<R־GDWL BJM\n",
      "GDWL BJM W\n",
      "BJM WH\n",
      "JM WH>NJH\n",
      "WH>NJH XCBH L\n",
      "H>NJH XCBH LHCBR׃\n",
      "XCBH LHCBR׃ WJJR>W\n",
      "LHCBR׃ WJJR>W H\n",
      "WJJR>W HMLXJM W\n",
      "HMLXJM WJZ<QW >JC\n",
      "WJZ<QW >JC >L־>LHJW\n",
      ">JC >L־>LHJW WJVLW\n",
      ">L־>LHJW WJVLW >T־\n",
      ">LHJW WJVLW >T־H\n",
      "WJVLW >T־HKLJM\n",
      ">T־HKLJM >CR B\n",
      "HKLJM >CR B\n",
      ">CR B>NJH >L־\n",
      "B>NJH >L־H\n",
      ">NJH >L־HJM\n",
      ">L־HJM LHQL\n",
      "HJM LHQL M\n",
      "LHQL M<LJHM W\n",
      "M<LJHM WJWNH JRD\n",
      "WJWNH JRD >L־JRKTJ\n",
      "JRD >L־JRKTJ HSPJNH\n",
      ">L־JRKTJ HSPJNH W\n",
      "JRKTJ HSPJNH WJCKB\n",
      "HSPJNH WJCKB W\n",
      "WJCKB WJRDM׃ W\n",
      "WJRDM׃ WJQRB >LJW\n",
      "WJQRB >LJW RB H\n",
      ">LJW RB HXBL W\n",
      "RB HXBL WJ>MR\n",
      "HXBL WJ>MR LW\n",
      "WJ>MR LW MH־LK\n",
      "LW MH־LK NRDM QWM\n",
      "MH־LK NRDM QWM QR>\n",
      "LK NRDM QWM QR> >L־\n",
      "NRDM QWM QR> >L־>LHJK\n",
      "QWM QR> >L־>LHJK >WLJ\n",
      "QR> >L־>LHJK >WLJ JT<CT\n",
      ">L־>LHJK >WLJ JT<CT H\n",
      ">LHJK >WLJ JT<CT H>LHJM\n",
      ">WLJ JT<CT H>LHJM LNW\n",
      "JT<CT H>LHJM LNW W\n",
      "H>LHJM LNW WL>\n",
      "LNW WL> N>BD׃ W\n",
      "WL> N>BD׃ WJ>MRW\n",
      "N>BD׃ WJ>MRW >JC >L־\n",
      "WJ>MRW >JC >L־R<HW\n",
      ">JC >L־R<HW LKW W\n",
      ">L־R<HW LKW WNPJLH\n",
      "R<HW LKW WNPJLH GWRLWT\n",
      "LKW WNPJLH GWRLWT W\n",
      "WNPJLH GWRLWT WND<H\n",
      "GWRLWT WND<H BC\n",
      "WND<H BCL\n",
      "BCLMJ H\n",
      "CLMJ HR<H\n",
      "LMJ HR<H H\n",
      "HR<H HZ>T LNW\n",
      "HZ>T LNW WJPLW\n",
      "LNW WJPLW GWRLWT W\n",
      "WJPLW GWRLWT WJPL\n",
      "GWRLWT WJPL HGWRL\n",
      "WJPL HGWRL <L־\n",
      "HGWRL <L־JWNH׃ W\n",
      "<L־JWNH׃ WJ>MRW >LJW\n",
      "JWNH׃ WJ>MRW >LJW HGJDH־\n",
      "WJ>MRW >LJW HGJDH־N>\n",
      ">LJW HGJDH־N> LNW B\n",
      "HGJDH־N> LNW B>CR\n",
      "N> LNW B>CR L\n",
      "LNW B>CR LMJ־\n",
      "B>CR LMJ־H\n",
      "LMJ־HR<H H\n",
      "HR<H HZ>T LNW\n",
      "HZ>T LNW MH־ML>KTK\n",
      "LNW MH־ML>KTK WM\n",
      "MH־ML>KTK WM>JN\n",
      "ML>KTK WM>JN TBW>\n",
      "WM>JN TBW> MH\n",
      "M>JN TBW> MH >RYK\n",
      "TBW> MH >RYK W>J־\n",
      "MH >RYK W>J־M\n",
      ">RYK W>J־MZH\n",
      "W>J־MZH <M\n",
      "MZH <M >TH׃ W\n",
      "<M >TH׃ WJ>MR >LJHM\n",
      ">TH׃ WJ>MR >LJHM <BRJ\n",
      "WJ>MR >LJHM <BRJ >NKJ\n",
      ">LJHM <BRJ >NKJ W>T־\n",
      "<BRJ >NKJ W>T־JHWH\n",
      ">NKJ W>T־JHWH >LHJ\n",
      "W>T־JHWH >LHJ H\n",
      "JHWH >LHJ HCMJM >NJ\n",
      ">LHJ HCMJM >NJ JR>\n",
      "HCMJM >NJ JR> >CR־\n",
      ">NJ JR> >CR־<FH >T־\n",
      "JR> >CR־<FH >T־H\n",
      ">CR־<FH >T־HJM\n",
      "<FH >T־HJM W\n",
      ">T־HJM W>T־\n",
      "HJM W>T־H\n",
      "W>T־HJBCH׃ W\n",
      "HJBCH׃ WJJR>W H\n",
      "WJJR>W H>NCJM JR>H\n",
      "H>NCJM JR>H GDWLH W\n",
      "JR>H GDWLH WJ>MRW >LJW\n",
      "GDWLH WJ>MRW >LJW MH־\n",
      "WJ>MRW >LJW MH־Z>T\n",
      ">LJW MH־Z>T <FJT KJ־\n",
      "MH־Z>T <FJT KJ־JD<W\n",
      "Z>T <FJT KJ־JD<W H\n",
      "<FJT KJ־JD<W H>NCJM\n",
      "KJ־JD<W H>NCJM KJ־\n",
      "JD<W H>NCJM KJ־M\n",
      "H>NCJM KJ־ML\n",
      "KJ־MLPNJ JHWH\n",
      "MLPNJ JHWH HW>\n",
      "LPNJ JHWH HW> BRX\n",
      "JHWH HW> BRX KJ HGJD\n",
      "HW> BRX KJ HGJD LHM׃\n",
      "BRX KJ HGJD LHM׃ W\n",
      "KJ HGJD LHM׃ WJ>MRW\n",
      "HGJD LHM׃ WJ>MRW >LJW\n",
      "LHM׃ WJ>MRW >LJW MH־\n",
      "WJ>MRW >LJW MH־N<FH\n",
      ">LJW MH־N<FH LK W\n",
      "MH־N<FH LK WJCTQ\n",
      "N<FH LK WJCTQ H\n",
      "LK WJCTQ HJM\n",
      "WJCTQ HJM M\n",
      "HJM M<LJNW KJ\n",
      "M<LJNW KJ HJM\n",
      "KJ HJM HWLK W\n",
      "HJM HWLK WS<R׃\n",
      "HWLK WS<R׃ WJ>MR\n",
      "WS<R׃ WJ>MR >LJHM\n",
      "WJ>MR >LJHM F>WNJ W\n",
      ">LJHM F>WNJ WHVJLNJ >L־\n",
      "F>WNJ WHVJLNJ >L־H\n",
      "WHVJLNJ >L־HJM\n",
      ">L־HJM WJCTQ\n",
      "HJM WJCTQ H\n",
      "WJCTQ HJM M\n",
      "HJM M<LJKM KJ\n",
      "M<LJKM KJ JWD< >NJ\n",
      "KJ JWD< >NJ KJ B\n",
      "JWD< >NJ KJ BC\n",
      ">NJ KJ BCLJ\n",
      "KJ BCLJ H\n",
      "BCLJ HS<R\n",
      "CLJ HS<R H\n",
      "HS<R HGDWL H\n",
      "HGDWL HZH <LJKM׃\n",
      "HZH <LJKM׃ WJXTRW\n",
      "<LJKM׃ WJXTRW H>NCJM\n",
      "WJXTRW H>NCJM L\n",
      "H>NCJM LHCJB >L־\n",
      "LHCJB >L־HJBCH\n",
      ">L־HJBCH WL>\n",
      "HJBCH WL> JKLW\n",
      "WL> JKLW KJ H\n",
      "JKLW KJ HJM HWLK\n",
      "KJ HJM HWLK W\n",
      "HJM HWLK WS<R\n",
      "HWLK WS<R <LJHM׃ W\n",
      "WS<R <LJHM׃ WJQR>W\n",
      "<LJHM׃ WJQR>W >L־JHWH\n",
      "WJQR>W >L־JHWH W\n",
      ">L־JHWH WJ>MRW >NH\n",
      "JHWH WJ>MRW >NH JHWH\n",
      "WJ>MRW >NH JHWH >L־\n",
      ">NH JHWH >L־N> N>BDH\n",
      "JHWH >L־N> N>BDH B\n",
      ">L־N> N>BDH BNPC\n",
      "N> N>BDH BNPC H\n",
      "N>BDH BNPC H>JC\n",
      "BNPC H>JC H\n",
      "H>JC HZH W\n",
      "HZH W>L־TTN\n",
      "W>L־TTN <LJNW DM\n",
      "TTN <LJNW DM NQJ> KJ־\n",
      "<LJNW DM NQJ> KJ־>TH\n",
      "DM NQJ> KJ־>TH JHWH\n",
      "NQJ> KJ־>TH JHWH K\n",
      "KJ־>TH JHWH K>CR\n",
      ">TH JHWH K>CR XPYT\n",
      "JHWH K>CR XPYT <FJT׃\n",
      "K>CR XPYT <FJT׃ W\n",
      "XPYT <FJT׃ WJF>W >T־\n",
      "<FJT׃ WJF>W >T־JWNH\n",
      "WJF>W >T־JWNH W\n",
      ">T־JWNH WJVLHW >L־\n",
      "JWNH WJVLHW >L־H\n",
      "WJVLHW >L־HJM\n",
      ">L־HJM WJ<MD\n",
      "HJM WJ<MD H\n",
      "WJ<MD HJM M\n",
      "HJM MZ<PW׃ W\n",
      "MZ<PW׃ WJJR>W H\n",
      "WJJR>W H>NCJM JR>H\n",
      "H>NCJM JR>H GDWLH >T־\n",
      "JR>H GDWLH >T־JHWH W\n",
      "GDWLH >T־JHWH WJZBXW־\n",
      ">T־JHWH WJZBXW־ZBX\n",
      "JHWH WJZBXW־ZBX L\n",
      "WJZBXW־ZBX LJHWH\n",
      "ZBX LJHWH WJDRW\n",
      "LJHWH WJDRW NDRJM׃\n",
      "WJDRW NDRJM׃ WJMN\n",
      "NDRJM׃ WJMN JHWH DG\n",
      "WJMN JHWH DG GDWL\n",
      "JHWH DG GDWL LBL<\n",
      "DG GDWL LBL< >T־\n",
      "GDWL LBL< >T־JWNH\n",
      "LBL< >T־JWNH W\n",
      ">T־JWNH WJHJ JWNH\n",
      "JWNH WJHJ JWNH B\n",
      "WJHJ JWNH BM<J\n",
      "JWNH BM<J HDG\n",
      "BM<J HDG CLCH\n",
      "HDG CLCH JMJM W\n",
      "CLCH JMJM WCLCH LJLWT׃\n",
      "JMJM WCLCH LJLWT׃ W\n",
      "WCLCH LJLWT׃ WJTPLL\n",
      "LJLWT׃ WJTPLL JWNH >L־\n",
      "WJTPLL JWNH >L־JHWH\n",
      "JWNH >L־JHWH >LHJW M\n",
      ">L־JHWH >LHJW MM<J\n",
      "JHWH >LHJW MM<J H\n",
      ">LHJW MM<J HDGH׃\n",
      "MM<J HDGH׃ W\n",
      "HDGH׃ WJ>MR QR>TJ\n",
      "WJ>MR QR>TJ MYRH\n",
      "QR>TJ MYRH LJ >L־\n",
      "MYRH LJ >L־JHWH\n",
      "LJ >L־JHWH WJ<NNJ\n",
      ">L־JHWH WJ<NNJ M\n",
      "JHWH WJ<NNJ MBVN\n",
      "WJ<NNJ MBVN C>WL\n",
      "MBVN C>WL CW<TJ CM<T\n",
      "C>WL CW<TJ CM<T QWLJ׃ W\n",
      "CW<TJ CM<T QWLJ׃ WTCLJKNJ\n",
      "CM<T QWLJ׃ WTCLJKNJ MYWLH\n",
      "QWLJ׃ WTCLJKNJ MYWLH B\n",
      "WTCLJKNJ MYWLH BLBB\n",
      "MYWLH BLBB JMJM W\n",
      "BLBB JMJM WNHR\n",
      "JMJM WNHR JSBBNJ KL־\n",
      "WNHR JSBBNJ KL־MCBRJK\n",
      "JSBBNJ KL־MCBRJK WGLJK\n",
      "KL־MCBRJK WGLJK <LJ\n",
      "MCBRJK WGLJK <LJ <BRW׃\n",
      "WGLJK <LJ <BRW׃ W\n",
      "<LJ <BRW׃ W>NJ >MRTJ\n",
      "<BRW׃ W>NJ >MRTJ NGRCTJ\n",
      "W>NJ >MRTJ NGRCTJ M\n",
      ">MRTJ NGRCTJ MNGD <JNJK\n",
      "NGRCTJ MNGD <JNJK >K\n",
      "MNGD <JNJK >K >WSJP\n",
      "<JNJK >K >WSJP LHBJV\n",
      ">K >WSJP LHBJV >L־\n",
      ">WSJP LHBJV >L־HJKL\n",
      "LHBJV >L־HJKL QDCK׃\n",
      ">L־HJKL QDCK׃ >PPWNJ MJM\n",
      "HJKL QDCK׃ >PPWNJ MJM <D־\n",
      "QDCK׃ >PPWNJ MJM <D־NPC\n",
      ">PPWNJ MJM <D־NPC THWM\n",
      "MJM <D־NPC THWM JSBBNJ\n",
      "<D־NPC THWM JSBBNJ SWP\n",
      "NPC THWM JSBBNJ SWP XBWC\n",
      "THWM JSBBNJ SWP XBWC L\n",
      "JSBBNJ SWP XBWC LR>CJ׃\n",
      "SWP XBWC LR>CJ׃ L\n",
      "XBWC LR>CJ׃ LQYBJ\n",
      "LR>CJ׃ LQYBJ HRJM\n",
      "LQYBJ HRJM JRDTJ H\n",
      "HRJM JRDTJ H>RY BRXJH\n",
      "JRDTJ H>RY BRXJH B<DJ\n",
      "H>RY BRXJH B<DJ L\n",
      "BRXJH B<DJ L<WLM W\n",
      "B<DJ L<WLM WT<L\n",
      "L<WLM WT<L M\n",
      "WT<L MCXT XJJ\n",
      "MCXT XJJ JHWH >LHJ׃\n",
      "XJJ JHWH >LHJ׃ BHT<VP\n",
      "JHWH >LHJ׃ BHT<VP <LJ\n",
      ">LHJ׃ BHT<VP <LJ NPCJ\n",
      "BHT<VP <LJ NPCJ >T־\n",
      "<LJ NPCJ >T־JHWH ZKRTJ\n",
      "NPCJ >T־JHWH ZKRTJ W\n",
      ">T־JHWH ZKRTJ WTBW>\n",
      "JHWH ZKRTJ WTBW> >LJK\n",
      "ZKRTJ WTBW> >LJK TPLTJ\n",
      "WTBW> >LJK TPLTJ >L־\n",
      ">LJK TPLTJ >L־HJKL QDCK׃\n",
      "TPLTJ >L־HJKL QDCK׃ MCMRJM\n",
      ">L־HJKL QDCK׃ MCMRJM HBLJ־\n",
      "HJKL QDCK׃ MCMRJM HBLJ־CW>\n",
      "QDCK׃ MCMRJM HBLJ־CW> XSDM\n",
      "MCMRJM HBLJ־CW> XSDM J<ZBW׃\n",
      "HBLJ־CW> XSDM J<ZBW׃ W\n",
      "CW> XSDM J<ZBW׃ W>NJ\n",
      "XSDM J<ZBW׃ W>NJ B\n",
      "J<ZBW׃ W>NJ BQWL\n",
      "W>NJ BQWL TWDH\n",
      "BQWL TWDH >ZBXH־LK\n",
      "TWDH >ZBXH־LK >CR NDRTJ\n",
      ">ZBXH־LK >CR NDRTJ >CLMH\n",
      "LK >CR NDRTJ >CLMH JCW<TH\n",
      ">CR NDRTJ >CLMH JCW<TH L\n",
      "NDRTJ >CLMH JCW<TH LJHWH׃ ס\n",
      ">CLMH JCW<TH LJHWH׃ ס W\n",
      "JCW<TH LJHWH׃ ס WJ>MR\n",
      "LJHWH׃ ס WJ>MR JHWH\n",
      "WJ>MR JHWH L\n",
      "JHWH LDG W\n",
      "LDG WJQ>\n",
      "DG WJQ> >T־\n",
      "WJQ> >T־JWNH >L־\n",
      ">T־JWNH >L־HJBCH׃ פ\n",
      "JWNH >L־HJBCH׃ פ W\n",
      ">L־HJBCH׃ פ WJHJ\n",
      "HJBCH׃ פ WJHJ DBR־\n",
      "WJHJ DBR־JHWH >L־\n",
      "DBR־JHWH >L־JWNH CNJT\n",
      "JHWH >L־JWNH CNJT L\n",
      ">L־JWNH CNJT L>MR׃\n",
      "JWNH CNJT L>MR׃ QWM\n",
      "CNJT L>MR׃ QWM LK\n",
      "L>MR׃ QWM LK >L־\n",
      "QWM LK >L־NJNWH H\n",
      "LK >L־NJNWH H<JR\n",
      ">L־NJNWH H<JR H\n",
      "NJNWH H<JR HGDWLH\n",
      "H<JR HGDWLH W\n",
      "HGDWLH WQR> >LJH\n",
      "WQR> >LJH >T־H\n",
      ">LJH >T־HQRJ>H >CR\n",
      ">T־HQRJ>H >CR >NKJ\n",
      "HQRJ>H >CR >NKJ DBR\n",
      ">CR >NKJ DBR >LJK׃ W\n",
      ">NKJ DBR >LJK׃ WJQM\n",
      "DBR >LJK׃ WJQM JWNH\n",
      ">LJK׃ WJQM JWNH W\n",
      "WJQM JWNH WJLK\n",
      "JWNH WJLK >L־NJNWH\n",
      "WJLK >L־NJNWH K\n",
      ">L־NJNWH KDBR JHWH\n",
      "NJNWH KDBR JHWH W\n",
      "KDBR JHWH WNJNWH\n",
      "JHWH WNJNWH HJTH <JR־\n",
      "WNJNWH HJTH <JR־GDWLH\n",
      "HJTH <JR־GDWLH L>LHJM\n",
      "<JR־GDWLH L>LHJM MHLK\n",
      "GDWLH L>LHJM MHLK CLCT\n",
      "L>LHJM MHLK CLCT JMJM׃\n",
      "MHLK CLCT JMJM׃ WJXL\n",
      "CLCT JMJM׃ WJXL JWNH\n",
      "JMJM׃ WJXL JWNH L\n",
      "WJXL JWNH LBW>\n",
      "JWNH LBW> B\n",
      "LBW> B<JR\n",
      "B<JR MHLK JWM\n",
      "<JR MHLK JWM >XD\n",
      "MHLK JWM >XD WJQR>\n",
      "JWM >XD WJQR> W\n",
      ">XD WJQR> WJ>MR\n",
      "WJQR> WJ>MR <WD\n",
      "WJ>MR <WD >RB<JM JWM\n",
      "<WD >RB<JM JWM WNJNWH\n",
      ">RB<JM JWM WNJNWH NHPKT׃\n",
      "JWM WNJNWH NHPKT׃ W\n",
      "WNJNWH NHPKT׃ WJ>MJNW\n",
      "NHPKT׃ WJ>MJNW >NCJ NJNWH\n",
      "WJ>MJNW >NCJ NJNWH B\n",
      ">NCJ NJNWH B>LHJM W\n",
      "NJNWH B>LHJM WJQR>W־\n",
      "B>LHJM WJQR>W־YWM\n",
      "WJQR>W־YWM WJLBCW\n",
      "YWM WJLBCW FQJM M\n",
      "WJLBCW FQJM MGDWLM\n",
      "FQJM MGDWLM W<D־\n",
      "MGDWLM W<D־QVNM׃\n",
      "W<D־QVNM׃ WJG<\n",
      "QVNM׃ WJG< HDBR\n",
      "WJG< HDBR >L־\n",
      "HDBR >L־MLK NJNWH\n",
      ">L־MLK NJNWH WJQM\n",
      "MLK NJNWH WJQM M\n",
      "NJNWH WJQM MKS>W\n",
      "WJQM MKS>W W\n",
      "MKS>W WJ<BR >DRTW\n",
      "WJ<BR >DRTW M<LJW\n",
      ">DRTW M<LJW WJKS\n",
      "M<LJW WJKS FQ\n",
      "WJKS FQ WJCB\n",
      "FQ WJCB <L־H\n",
      "WJCB <L־H>PR׃\n",
      "<L־H>PR׃ WJZ<Q\n",
      "H>PR׃ WJZ<Q W\n",
      "WJZ<Q WJ>MR B\n",
      "WJ>MR BNJNWH M\n",
      "BNJNWH MV<M H\n",
      "MV<M HMLK W\n",
      "HMLK WGDLJW L\n",
      "WGDLJW L>MR H\n",
      "L>MR H>DM W\n",
      "H>DM WHBHMH\n",
      "WHBHMH HBQR\n",
      "HBHMH HBQR W\n",
      "HBQR WHY>N\n",
      "WHY>N >L־JV<MW\n",
      "HY>N >L־JV<MW M>WMH\n",
      ">L־JV<MW M>WMH >L־JR<W\n",
      "JV<MW M>WMH >L־JR<W W\n",
      "M>WMH >L־JR<W WMJM\n",
      ">L־JR<W WMJM >L־\n",
      "JR<W WMJM >L־JCTW׃\n",
      "WMJM >L־JCTW׃ W\n",
      ">L־JCTW׃ WJTKSW FQJM\n",
      "JCTW׃ WJTKSW FQJM H\n",
      "WJTKSW FQJM H>DM\n",
      "FQJM H>DM WH\n",
      "H>DM WHBHMH\n",
      "WHBHMH WJQR>W\n",
      "HBHMH WJQR>W >L־\n",
      "WJQR>W >L־>LHJM B\n",
      ">L־>LHJM BXZQH W\n",
      ">LHJM BXZQH WJCBW\n",
      "BXZQH WJCBW >JC\n",
      "WJCBW >JC MDRKW\n",
      ">JC MDRKW HR<H\n",
      "MDRKW HR<H W\n",
      "HR<H WMN־H\n",
      "WMN־HXMS >CR\n",
      "HXMS >CR BKPJHM׃\n",
      ">CR BKPJHM׃ MJ־JWD<\n",
      "BKPJHM׃ MJ־JWD< JCWB\n",
      "MJ־JWD< JCWB WNXM\n",
      "JWD< JCWB WNXM H\n",
      "JCWB WNXM H>LHJM\n",
      "WNXM H>LHJM W\n",
      "H>LHJM WCB M\n",
      "WCB MXRWN >PW\n",
      "MXRWN >PW WL>\n",
      ">PW WL> N>BD׃ W\n",
      "WL> N>BD׃ WJR>\n",
      "N>BD׃ WJR> H>LHJM\n",
      "WJR> H>LHJM >T־\n",
      "H>LHJM >T־M<FJHM KJ־\n",
      ">T־M<FJHM KJ־CBW M\n",
      "M<FJHM KJ־CBW MDRKM\n",
      "KJ־CBW MDRKM H\n",
      "CBW MDRKM HR<H\n",
      "MDRKM HR<H W\n",
      "HR<H WJNXM H\n",
      "WJNXM H>LHJM <L־\n",
      "H>LHJM <L־HR<H\n",
      "<L־HR<H >CR־DBR\n",
      "HR<H >CR־DBR L\n",
      ">CR־DBR L<FWT־LHM\n",
      "DBR L<FWT־LHM W\n",
      "L<FWT־LHM WL>\n",
      "LHM WL> <FH׃ W\n",
      "WL> <FH׃ WJR<\n",
      "<FH׃ WJR< >L־JWNH\n",
      "WJR< >L־JWNH R<H\n",
      ">L־JWNH R<H GDWLH W\n",
      "JWNH R<H GDWLH WJXR\n",
      "R<H GDWLH WJXR LW׃\n",
      "GDWLH WJXR LW׃ W\n",
      "WJXR LW׃ WJTPLL\n",
      "LW׃ WJTPLL >L־JHWH\n",
      "WJTPLL >L־JHWH W\n",
      ">L־JHWH WJ>MR >NH\n",
      "JHWH WJ>MR >NH JHWH\n",
      "WJ>MR >NH JHWH H\n",
      ">NH JHWH HLW>־ZH\n",
      "JHWH HLW>־ZH DBRJ\n",
      "HLW>־ZH DBRJ <D־\n",
      "ZH DBRJ <D־HJWTJ <L־\n",
      "DBRJ <D־HJWTJ <L־>DMTJ\n",
      "<D־HJWTJ <L־>DMTJ <L־\n",
      "HJWTJ <L־>DMTJ <L־KN\n",
      "<L־>DMTJ <L־KN QDMTJ\n",
      ">DMTJ <L־KN QDMTJ L\n",
      "<L־KN QDMTJ LBRX\n",
      "KN QDMTJ LBRX TRCJCH\n",
      "QDMTJ LBRX TRCJCH KJ\n",
      "LBRX TRCJCH KJ JD<TJ\n",
      "TRCJCH KJ JD<TJ KJ >TH\n",
      "KJ JD<TJ KJ >TH >L־\n",
      "JD<TJ KJ >TH >L־XNWN\n",
      "KJ >TH >L־XNWN W\n",
      ">TH >L־XNWN WRXWM\n",
      ">L־XNWN WRXWM >RK\n",
      "XNWN WRXWM >RK >PJM\n",
      "WRXWM >RK >PJM W\n",
      ">RK >PJM WRB־XSD\n",
      ">PJM WRB־XSD W\n",
      "WRB־XSD WNXM\n",
      "XSD WNXM <L־H\n",
      "WNXM <L־HR<H׃\n",
      "<L־HR<H׃ W<TH\n",
      "HR<H׃ W<TH JHWH\n",
      "W<TH JHWH QX־N>\n",
      "JHWH QX־N> >T־NPCJ\n",
      "QX־N> >T־NPCJ MMNJ\n",
      "N> >T־NPCJ MMNJ KJ\n",
      ">T־NPCJ MMNJ KJ VWB\n",
      "NPCJ MMNJ KJ VWB MWTJ\n",
      "MMNJ KJ VWB MWTJ M\n",
      "KJ VWB MWTJ MXJJ׃ ס\n",
      "VWB MWTJ MXJJ׃ ס W\n",
      "MWTJ MXJJ׃ ס WJ>MR\n",
      "MXJJ׃ ס WJ>MR JHWH\n",
      "WJ>MR JHWH HHJVB\n",
      "JHWH HHJVB XRH LK׃\n",
      "HHJVB XRH LK׃ W\n",
      "XRH LK׃ WJY> JWNH\n",
      "LK׃ WJY> JWNH MN־\n",
      "WJY> JWNH MN־H\n",
      "JWNH MN־H<JR W\n",
      "MN־H<JR WJCB\n",
      "H<JR WJCB M\n",
      "WJCB MQDM L\n",
      "MQDM L<JR\n",
      "L<JR WJ<F\n",
      "<JR WJ<F LW\n",
      "WJ<F LW CM SKH\n",
      "LW CM SKH WJCB\n",
      "CM SKH WJCB TXTJH\n",
      "SKH WJCB TXTJH B\n",
      "WJCB TXTJH B\n",
      "TXTJH BYL <D\n",
      "BYL <D >CR\n",
      "YL <D >CR JR>H\n",
      "<D >CR JR>H MH־JHJH\n",
      ">CR JR>H MH־JHJH B\n",
      "JR>H MH־JHJH B\n",
      "MH־JHJH B<JR׃\n",
      "JHJH B<JR׃ W\n",
      "B<JR׃ WJMN\n",
      "<JR׃ WJMN JHWH־\n",
      "WJMN JHWH־>LHJM QJQJWN\n",
      "JHWH־>LHJM QJQJWN WJ<L׀\n",
      ">LHJM QJQJWN WJ<L׀ M\n",
      "QJQJWN WJ<L׀ M<L\n",
      "WJ<L׀ M<L L\n",
      "M<L LJWNH L\n",
      "LJWNH LHJWT YL\n",
      "LHJWT YL <L־R>CW\n",
      "YL <L־R>CW LHYJL\n",
      "<L־R>CW LHYJL LW\n",
      "R>CW LHYJL LW M\n",
      "LHYJL LW MR<TW\n",
      "LW MR<TW WJFMX\n",
      "MR<TW WJFMX JWNH\n",
      "WJFMX JWNH <L־H\n",
      "JWNH <L־HQJQJWN FMXH\n",
      "<L־HQJQJWN FMXH GDWLH׃\n",
      "HQJQJWN FMXH GDWLH׃ W\n",
      "FMXH GDWLH׃ WJMN H\n",
      "GDWLH׃ WJMN H>LHJM\n",
      "WJMN H>LHJM TWL<T\n",
      "H>LHJM TWL<T B<LWT\n",
      "TWL<T B<LWT HCXR\n",
      "B<LWT HCXR L\n",
      "HCXR LMXRT\n",
      "LMXRT WTK\n",
      "MXRT WTK >T־\n",
      "WTK >T־HQJQJWN\n",
      ">T־HQJQJWN WJJBC׃\n",
      "HQJQJWN WJJBC׃ W\n",
      "WJJBC׃ WJHJ׀ K\n",
      "WJHJ׀ KZRX H\n",
      "KZRX HCMC W\n",
      "HCMC WJMN >LHJM\n",
      "WJMN >LHJM RWX QDJM\n",
      ">LHJM RWX QDJM XRJCJT W\n",
      "RWX QDJM XRJCJT WTK\n",
      "QDJM XRJCJT WTK H\n",
      "XRJCJT WTK HCMC\n",
      "WTK HCMC <L־\n",
      "HCMC <L־R>C JWNH\n",
      "<L־R>C JWNH WJT<LP\n",
      "R>C JWNH WJT<LP W\n",
      "JWNH WJT<LP WJC>L\n",
      "WJT<LP WJC>L >T־\n",
      "WJC>L >T־NPCW L\n",
      ">T־NPCW LMWT W\n",
      "NPCW LMWT WJ>MR\n",
      "LMWT WJ>MR VWB\n",
      "WJ>MR VWB MWTJ M\n",
      "VWB MWTJ MXJJ׃ W\n",
      "MWTJ MXJJ׃ WJ>MR\n",
      "MXJJ׃ WJ>MR >LHJM\n",
      "WJ>MR >LHJM >L־JWNH\n",
      ">LHJM >L־JWNH HHJVB\n",
      ">L־JWNH HHJVB XRH־\n",
      "JWNH HHJVB XRH־LK\n",
      "HHJVB XRH־LK <L־\n",
      "XRH־LK <L־HQJQJWN\n",
      "LK <L־HQJQJWN W\n",
      "<L־HQJQJWN WJ>MR\n",
      "HQJQJWN WJ>MR HJVB\n",
      "WJ>MR HJVB XRH־LJ\n",
      "HJVB XRH־LJ <D־MWT׃\n",
      "XRH־LJ <D־MWT׃ W\n",
      "LJ <D־MWT׃ WJ>MR\n",
      "<D־MWT׃ WJ>MR JHWH\n",
      "MWT׃ WJ>MR JHWH >TH\n",
      "WJ>MR JHWH >TH XST\n",
      "JHWH >TH XST <L־H\n",
      ">TH XST <L־HQJQJWN\n",
      "XST <L־HQJQJWN >CR\n",
      "<L־HQJQJWN >CR L>־\n",
      "HQJQJWN >CR L>־<MLT\n",
      ">CR L>־<MLT BW W\n",
      "L>־<MLT BW WL>\n",
      "<MLT BW WL> GDLTW\n",
      "BW WL> GDLTW C\n",
      "WL> GDLTW CBN־\n",
      "GDLTW CBN־LJLH HJH\n",
      "CBN־LJLH HJH W\n",
      "LJLH HJH WBN־LJLH\n",
      "HJH WBN־LJLH >BD׃\n",
      "WBN־LJLH >BD׃ W\n",
      "LJLH >BD׃ W>NJ L>\n",
      ">BD׃ W>NJ L> >XWS\n",
      "W>NJ L> >XWS <L־\n",
      "L> >XWS <L־NJNWH H\n",
      ">XWS <L־NJNWH H<JR\n",
      "<L־NJNWH H<JR H\n",
      "NJNWH H<JR HGDWLH\n",
      "H<JR HGDWLH >CR\n",
      "HGDWLH >CR JC־BH\n",
      ">CR JC־BH HRBH M\n",
      "JC־BH HRBH MCTJM־\n",
      "BH HRBH MCTJM־<FRH\n",
      "HRBH MCTJM־<FRH RBW\n",
      "MCTJM־<FRH RBW >DM\n",
      "<FRH RBW >DM >CR L>־\n",
      "RBW >DM >CR L>־JD<\n",
      ">DM >CR L>־JD< BJN־\n",
      ">CR L>־JD< BJN־JMJNW\n",
      "L>־JD< BJN־JMJNW L\n",
      "JD< BJN־JMJNW LFM>LW\n",
      "BJN־JMJNW LFM>LW W\n"
     ]
    }
   ],
   "source": [
    "test_clauses, output_test = prepare_test_data()\n",
    "tokenized_test_data, _, _ = one_hot_encode(len(test_clauses), max_len_input, max_len_output, input_chars, output_vocab, input_char2idx, output_char2idx, test_clauses, output_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_31 (InputLayer)           (None, None, 31)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_31 (LSTM)                  [(None, None, 512),  1114112     input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_32 (InputLayer)           (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_32 (LSTM)                  [(None, 512), (None, 2099200     lstm_31[0][0]                    \n",
      "                                                                 lstm_31[0][1]                    \n",
      "                                                                 lstm_31[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_33 (LSTM)                  [(None, None, 512),  1058816     input_32[0][0]                   \n",
      "                                                                 lstm_32[0][1]                    \n",
      "                                                                 lstm_32[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, None, 4)      2052        lstm_33[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,274,180\n",
      "Trainable params: 4,274,180\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 270000 samples, validate on 30000 samples\n",
      "Epoch 1/20\n",
      "270000/270000 [==============================] - 187s 694us/step - loss: 0.2566 - val_loss: 0.2115\n",
      "Epoch 2/20\n",
      "270000/270000 [==============================] - 180s 667us/step - loss: 0.1900 - val_loss: 0.1753\n",
      "Epoch 3/20\n",
      "270000/270000 [==============================] - 181s 669us/step - loss: 0.1852 - val_loss: 0.1675\n",
      "Epoch 4/20\n",
      "270000/270000 [==============================] - 180s 668us/step - loss: 0.1913 - val_loss: 0.1684\n",
      "Epoch 5/20\n",
      "270000/270000 [==============================] - 180s 665us/step - loss: 0.1786 - val_loss: 0.1560\n",
      "Epoch 6/20\n",
      "270000/270000 [==============================] - 180s 665us/step - loss: 0.1358 - val_loss: 0.0958\n",
      "Epoch 7/20\n",
      "270000/270000 [==============================] - 180s 666us/step - loss: 0.1080 - val_loss: 0.0711\n",
      "Epoch 8/20\n",
      "270000/270000 [==============================] - 181s 670us/step - loss: 0.0628 - val_loss: 0.0570\n",
      "Epoch 9/20\n",
      "270000/270000 [==============================] - 180s 667us/step - loss: 0.0337 - val_loss: 0.0266\n",
      "Epoch 10/20\n",
      "270000/270000 [==============================] - 180s 666us/step - loss: 0.0259 - val_loss: 0.0194\n",
      "Epoch 11/20\n",
      "270000/270000 [==============================] - 179s 665us/step - loss: 0.0142 - val_loss: 0.0191\n",
      "Epoch 12/20\n",
      "270000/270000 [==============================] - 180s 666us/step - loss: 0.0509 - val_loss: 0.0172\n",
      "Epoch 13/20\n",
      "270000/270000 [==============================] - 180s 665us/step - loss: 0.0216 - val_loss: 0.0152\n",
      "Epoch 14/20\n",
      "270000/270000 [==============================] - 180s 667us/step - loss: 0.0103 - val_loss: 0.0141\n",
      "Epoch 15/20\n",
      "270000/270000 [==============================] - 180s 668us/step - loss: 0.0165 - val_loss: 0.0187\n",
      "Epoch 16/20\n",
      "270000/270000 [==============================] - 179s 664us/step - loss: 0.0087 - val_loss: 0.0113\n",
      "Epoch 17/20\n",
      "270000/270000 [==============================] - 179s 663us/step - loss: 0.0071 - val_loss: 0.0111\n",
      "Epoch 18/20\n",
      "270000/270000 [==============================] - 180s 666us/step - loss: 0.0063 - val_loss: 0.0099\n",
      "Epoch 19/20\n",
      "270000/270000 [==============================] - 179s 663us/step - loss: 0.0164 - val_loss: 0.0099\n",
      "Epoch 20/20\n",
      "270000/270000 [==============================] - 180s 665us/step - loss: 0.0056 - val_loss: 0.0097\n"
     ]
    }
   ],
   "source": [
    "encoder_input, encoder_states, decoder_input, decoder_LSTM, decoder_dense, model = define_LSTM_model(input_chars, output_vocab)\n",
    "model = compile_and_train(model, tokenized_input, tokenized_output, 512, 20, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference models for testing\n",
    "\n",
    "# Encoder inference model\n",
    "encoder_model_inf = Model(encoder_input, encoder_states)\n",
    "\n",
    "# Decoder inference model\n",
    "decoder_state_input_h = Input(shape=(512,))\n",
    "decoder_state_input_c = Input(shape=(512,))\n",
    "decoder_input_states = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_out, decoder_h, decoder_c = decoder_LSTM(decoder_input, \n",
    "                                                 initial_state=decoder_input_states)\n",
    "\n",
    "decoder_states = [decoder_h , decoder_c]\n",
    "\n",
    "decoder_out = decoder_dense(decoder_out)\n",
    "\n",
    "decoder_model_inf = Model(inputs=[decoder_input] + decoder_input_states,\n",
    "                          outputs=[decoder_out] + decoder_states )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_seq(inp_seq):\n",
    "    \n",
    "    # Initial states value is coming from the encoder \n",
    "    states_val = encoder_model_inf.predict(inp_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1, 1, len(output_vocab)))\n",
    "    target_seq[0, 0, output_char2idx['\\t']] = 1\n",
    "    \n",
    "    pred_pos = []\n",
    "    stop_condition = False\n",
    "    \n",
    "    while not stop_condition:\n",
    "        \n",
    "        decoder_out, decoder_h, decoder_c = decoder_model_inf.predict(x=[target_seq] + states_val)\n",
    "        max_val_index = np.argmax(decoder_out[0,-1,:])\n",
    "        sampled_out_char = output_idx2char[max_val_index]\n",
    "        pred_pos.append(sampled_out_char)\n",
    "        \n",
    "        if (sampled_out_char == '\\n'):\n",
    "            stop_condition = True\n",
    "        \n",
    "        target_seq = np.zeros((1, 1, len(output_vocab)))\n",
    "        target_seq[0, 0, max_val_index] = 1\n",
    "        \n",
    "        states_val = [decoder_h, decoder_c]\n",
    "        \n",
    "    return pred_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input clause: JWNH LBRX TRCJCH MLPNJ\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: GDWL BJM WH>NJH\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'x', 'x', 'x', 'w', 'x', 'w', 'w', 'x', 'x', 'w', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: BJM WH>NJH\n",
      "Predicted phrase boundaries: ['w', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'w', 'x', 'x', 'w', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: WH>NJH XCBH LHCBR\n",
      "Predicted phrase boundaries: ['x', 'w', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: >T־HKLJM >CR B>NJH\n",
      "Predicted phrase boundaries: ['x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'w', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: HKLJM >CR B>NJH\n",
      "Predicted phrase boundaries: ['x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'w', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: B>NJH >L־HJM\n",
      "Predicted phrase boundaries: ['x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: >NJH >L־HJM\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'x', 'w', 'x', 'x', 'w', 'x', 'w', 'w', 'x', 'x', 'w']\n",
      "Input clause: ['w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: GWRLWT WND<H BCLMJ\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'w', 'x', 'w', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: WND<H BCLMJ\n",
      "Predicted phrase boundaries: ['x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'w', 'x', 'w', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: BCLMJ HR<H\n",
      "Predicted phrase boundaries: ['x', 'w', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'w', 'x', 'w', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: CLMJ HR<H\n",
      "Predicted phrase boundaries: ['w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'w', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'w', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: LNW MH־ML>KTK WM>JN\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'w', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'x', 'x', 'w', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: JD<W H>NCJM KJ־MLPNJ\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'w', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: H>NCJM KJ־MLPNJ\n",
      "Predicted phrase boundaries: ['x', 'w', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'w', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: KJ־MLPNJ JHWH\n",
      "Predicted phrase boundaries: ['x', 'x', 'w', 'x', 'w', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'x', 'w', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: KJ JWD< >NJ KJ BCLJ\n",
      "Predicted phrase boundaries: ['x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'w', 'x', 'w', 'x', 'w', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: JWD< >NJ KJ BCLJ\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'w', 'x', 'w', 'x', 'w', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: >NJ KJ BCLJ\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'w', 'x', 'x', 'w', 'x', 'w', 'w', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'x', 'x', 'w', 'x', 'x', 'w', 'x', 'w', 'x', 'w', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: KJ BCLJ HS<R\n",
      "Predicted phrase boundaries: ['x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'x', 'w', 'x', 'w', 'x', 'w', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: BCLJ HS<R\n",
      "Predicted phrase boundaries: ['x', 'w', 'w', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'w', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: CLJ HS<R HGDWL\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: MZ<PW׃ WJJR>W H>NCJM\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: JWNH BM<J HDG\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'x', 'w', 'x', 'w', 'w', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: HDG CLCH JMJM WCLCH\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: WTCLJKNJ MYWLH BLBB\n",
      "Predicted phrase boundaries: ['x', 'w', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: LHBJV >L־HJKL QDCK׃\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: L<WLM WT<L MCXT\n",
      "Predicted phrase boundaries: ['x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: MCXT XJJ JHWH >LHJ׃\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: WJ>MR JHWH LDG\n",
      "Predicted phrase boundaries: ['x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'w', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: JHWH LDG WJQ>\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'x', 'x', 'x', 'w', 'x', 'w', 'w', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: KDBR JHWH WNJNWH\n",
      "Predicted phrase boundaries: ['x', 'w', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input clause: JWNH LBW> B<JR\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'x', 'w', 'x', 'w', 'w', 'x', 'x', 'x', 'w', 'x', 'w', 'w', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'w', 'w', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: LBW> B<JR\n",
      "Predicted phrase boundaries: ['x', 'w', 'w', 'x', 'x', 'x', 'w', 'x', 'w', 'w', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'x', 'w', 'x', 'w', 'w', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: YWM WJLBCW FQJM MGDWLM\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: MLK NJNWH WJQM MKS>W\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: MKS>W WJ<BR >DRTW\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: WJZ<Q WJ>MR BNJNWH\n",
      "Predicted phrase boundaries: ['x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: WJ>MR BNJNWH MV<M\n",
      "Predicted phrase boundaries: ['x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: BNJNWH MV<M HMLK\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: MV<M HMLK WGDLJW\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: H>LHJM WCB MXRWN\n",
      "Predicted phrase boundaries: ['x', 'w', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: MMNJ KJ VWB MWTJ MXJJ\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'x', 'w', 'x', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'x', 'x', 'x', 'w', 'x', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: VWB MWTJ MXJJ׃ ס WJ>MR\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: MXJJ׃ ס WJ>MR JHWH\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: SKH WJCB TXTJH BYL\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'w', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: WJCB TXTJH BYL\n",
      "Predicted phrase boundaries: ['x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'w', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: M<L LJWNH LHJWT\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: HQJQJWN FMXH GDWLH׃ WJMN\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: B<LWT HCXR LMXRT\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'w', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: HQJQJWN WJJBC׃ WJHJ\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: VWB MWTJ MXJJ׃ WJ>MR\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: HQJQJWN WJ>MR HJVB\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: HQJQJWN >CR L>־<MLT\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'w', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: BW WL> GDLTW CBN\n",
      "Predicted phrase boundaries: ['x', 'x', 'w', 'x', 'w', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'x', 'w', 'x', 'w', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: WL> GDLTW CBN־\n",
      "Predicted phrase boundaries: ['x', 'w', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: GDLTW CBN־LJLH HJH\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: CBN־LJLH HJH WBN\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: >CR JC־BH HRBH MCTJM\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'w', 'x', 'x', 'w', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'x', 'x', 'w', 'x', 'x', 'w', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: JC־BH HRBH MCTJM־\n",
      "Predicted phrase boundaries: ['x', 'x', 'w', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'x', 'w', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: BH HRBH MCTJM־<FRH\n",
      "Predicted phrase boundaries: ['x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w']\n",
      "-\n",
      "Input clause: HRBH MCTJM־<FRH RBW\n",
      "Predicted phrase boundaries: ['x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'x', 'x', 'x', 'w', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'w']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input clause: MCTJM־<FRH RBW >DM\n",
      "Predicted phrase boundaries: ['x', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "Input clause: ['x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'w', 'x', 'x', 'x', 'w']\n",
      "640\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "\n",
    "for seq_index in range(len(output_test)):\n",
    "    inp_seq = tokenized_test_data[seq_index:seq_index+1]\n",
    "    \n",
    "    pred_pos = decode_seq(inp_seq)\n",
    "\n",
    "    if output_test[seq_index] == pred_pos[:-1]:\n",
    "        correct += 1\n",
    "    else:\n",
    "         print('-')\n",
    "         print('Input clause:', test_clauses[seq_index])\n",
    "         print('Predicted word boundaries:', pred_pos[:-1])\n",
    "         print('Input chunk:', output_test[seq_index])  \n",
    "        \n",
    "print(correct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9103840682788051"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct/len(output_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
